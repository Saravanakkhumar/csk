%\documentclass{acm-book-v2}
%\RequirePackage[errorshow]{tracefnt}
%%\newcommand{\mpage}[1]{}
%%\newcommand{\indexfn}[1]{}

%%\usepackage{showframe}

%\usepackage{custom-tooltip}
%\usepackage{custom-tooltip-Alt-Text-View}



%\begin{document}

\setcounter{chapter}{10}

\chapter{\label{chap:11}The Non-computable}

{The concept of computation is at the heart of algorithms and computers. As Alan Turing demonstrated, algorithms, despite their power, are not able to compute everything, to solve every problem. This chapter illustrates the limits of computability and introduces the features of the non-computable, and also discusses problems for which there is no available algorithm. Concepts such as common sense, intuition, and consciousness are discussed in the context of machine intelligence. The chapter concludes with some considerations and comparisons on the computability of human and artificial intelligence.}

\section{\label{sec:11.1}The Limits of Computation}

A problem is computable (i.e., solvable or decidable) if it can be resolved in principle by a computing machine, that is, if it may be coded in an algorithm. As we discussed in Chapter~\ExternalLink{chap:2}{2}, David Hilbert believed that all mathematical problems were solvable, that is, he was convinced that the question of whether there is a systematic way to find a solution to every mathematical problem had a positive answer. This became known as the ``decision problem.'' Problems of this form, which investigate the existence of an algorithm for deciding the truth or falsity of a whole category of statements, are called decision problems to differentiate them from normal mathematical questions regarding the truth or falsity of single propositions. A positive solution to a decision problem consists of providing an algorithm for solving it, whereas a negative solution consists of proving that no algorithm for solving that problem exists (i.e., the problem is unsolvable) [\citealt{chap:11:Martin:1958}]. In 1931, Kurt G\"{o}del published the incompleteness theorems that showed that for any formal system of axioms equipped with rules of inference satisfying certain minimal requirements, there exist questions that cannot be answered within that system (i.e., they are not solvable).

G\"{o}del's incompleteness theorems are the most important proven mathematical statements on the limitations of formal systems. A few years later, Alan Turing reformulated G\"{o}del's results on the limits of proof and computation, proving that his ``universal computing machine'' would be capable of performing any possible mathematical computation if it were representable as an algorithm. Turing deduced that if a computation problem cannot be expressed as an algorithm, that is, cannot be executed by a Turing machine, there is no solution for that problem. In particular, Alan Turing and Alonzo Church independently proved that a general solution to the ``decision problem'' is not possible. Initially, Turing proved the undecidability of the halting problem (i.e., the problem of determining, given a description of an arbitrary computer program and an input, whether the program will finish running or will run forever), then, as a corollary, he found the unsolvability of the ``decision problem.'' In their studies, it is assumed that the intuitive notion of ``effectively calculable,'' that is, computable through a mechanical method, is captured by the functions computable by a Turing machine or, equivalently, by those expressible in a formalism known as lambda calculus. As mentioned before, Turing proved the theorem that there is no algorithm to solve the halting problem. That problem is important because it was also one of the first problems to be proved as being undecidable. From this, we can say that computers are not able to compute everything. Therefore, they cannot solve all the problems that humans pose to them.

George Cantor was a German mathematician who provided a key contribution in the creation of set theory, the branch of mathematics that studies sets as collections of abstract objects. Cantor showed the significance of one-to-one correspondence between the members of two infinite sets and demonstrated that real numbers are more numerous than natural numbers. At the end of the nineteenth century, Cantor stated and proved a fundamental theorem that asserts that for any set \textit{S}, the set $P(S)$ of all subsets of \textit{S}, called the powerset of \textit{S}, has a strictly greater number of elements than \textit{S}, that is, has a strictly greater \textit{cardinality} than \textit{S} itself:\vspace*{-3pt}
\[
card\ (S)<card\ (P(A)).\vspace*{-3pt}
\]
As mentioned above, the cardinality of a set specifies the number of elements of the set. For example, the set $S = \{3,5,7,11\}$ contains four elements, and therefore \textit{S} has a cardinality of 4. The method used by Cantor in the proof of his theorem implies the existence of an infinity of infinities. As a consequence of Cantor's theorem, the cardinality of the real numbers, which is the same as that of the powerset of the integers, is strictly higher than the cardinality of the integers. Not all sets of integer numbers are computable. The halting problem is a well-known example of a non-computable set. The existence of many non-computable sets originates from the fact that there are only countably many Turing machines (in one-to-one correspondence with the set of natural numbers), and thus only countably many computable sets; but, according to Cantor's theorem, there are uncountably many sets of natural numbers, which contain too many elements to be countable. In other words, Turing machines can be seen as functions from non-negative integers, encoding the input, to non-negative integers, encoding the output. However, the class of functions implemented by Turing machines cannot be the same as the whole class of functions from the set of natural numbers to the same set. The number of Turing machines is only countably infinite because each machine can be mapped into a unique integer. Conversely, the whole class of functions from the natural numbers to the natural numbers, from Cantor theory can be shown to be uncountably infinite. Indeed, this class of functions has the same cardinality as the set of real numbers.

The Church--Turing thesis states that any real-world computation can be translated into an equivalent computation involving a Turing machine. The thesis \hbox{specifies} that all the functions that are effectively computable are in fact Turing computable, and vice versa, consequently restricting the notion of computability to the well-defined operations of Turing machines. This is a thesis, not a theorem, because there has never been a proof for it, but the evidence for its validity comes from the fact that every realistic model of computation yet discovered, has been shown to be equivalent. Recently, some scholars have argued that there exist functions that are computable by executing well-defined quantum mechanical procedures in a finite way that are not Turing computable. This, for example, is discussed by the Australian researcher Tien D. Kieu in an attempt to extend the concept of effective computability taking into account quantum mechanics principles [\citealt{chap:11:Kieu:2003}]. Kieu argues the possibility in principle of deciding some of the classical undecidables, Hilbert's tenth problem and thus the Turing halting problem in this instance. If the quantum algorithm is implemented, the Church--Turing thesis for effective computability should be modified accordingly.

After G\"{o}del's work on the incompleteness of formal systems and Church and Turing's work on the limits of computability, several mathematical problems have been shown to be undecidable. Problems such as the word problem for semigroups and groups (i.e., the problem of deciding whether two given expressions are equivalent with respect to a set of replacing identities) cannot be decided. In mathematics, a group is a set and an operation that combines any two elements of the set to create a third element of the same set, in such a way that the operation is associative, every element has an inverse, and an identity element exists. \hbox{A semigroup} is also a set with an operation that is associative, but differently from a group, the binary operation is not invertible. Undecidability of the word problem for semigroups was demonstrated by Markov and Post, whereas its generalization to groups was demonstrated by Novikov and Boone. Two decades later, the Russian mathematician and computer scientist Yuri V. Matiyasevich proved a theorem that took his name, which provided a negative answer to the Hilbert's tenth problem. Matiyasevich's theorem states:

\begin{quote}
Every computably enumerable set \textit{S} is Diophantine, and the converse.
\end{quote}

A set \textit{S} of integers is computably enumerable if there is an algorithm such that: for each integer input \textit{i}, if \textit{i} is a member of \textit{S}, then the algorithm eventually halts; otherwise, it runs forever. A Diophantine equation is a polynomial equation with integer coefficients and a finite number of unknowns in the form:
\[
D\ (x_{1} ,\ldots ,x_{m} )=0\qquad (m\ge 2).
\]
This equation was named after the Greek mathematician Diophantus who lived in the third century AD and worked in the city of Alexandria. He was the first mathematician to use symbols in Greek algebra. Hilbert's tenth problem asks for an effective algorithm that, for any given Diophantine equation, can decide whether the equation has a solution with all unknowns taking integer values. We can simply say Hilbert's tenth problem is a decision problem, that is, a problem consisting of infinitely many individual problems each of which requires a ``Yes'' or ``No'' answer. The heart of a decision problem is the request to find a single universal procedure that could be applied to each of the comprising individual problems. Matiyasevich's theorem proving that most computably enumerable sets are not decidable implies that Hilbert's tenth problem is unsolvable, that is, it has no effective solution. Indeed, Matiyasevich proved that:

\begin{quote}
There is no algorithm which, for a given arbitrary Diophantine equation, would tell whether the equation has a solution or not.
\end{quote}

Since 1970, Matiyasevich's theorem has also been used to prove that several problems from differential equations and infinitesimal calculus are unsolvable. As discussed by the American mathematician and computer scientist Martin \citet{chap:11:Davis:1973}, the unsolvability of Hilbert's tenth problem can also be used to obtain a strengthened form of the famous theorem of incompleteness proved by G\"{o}del that establishes that any finitely axiomatic, consistent mathematical system sufficiently complex to embrace arithmetic must be incomplete. This means that there exist some statements whose truth cannot be confirmed or denied from within the system (i.e., they are undecidable). Using Matiyasevich's theorem, G\"{o}del's theorem can be reformulated as follows:

\begin{quote}
Corresponding to any given axiomatization of number theory, there is a Diophantine equation, which has no positive integer solutions, but such that this fact cannot be proved within the given axiomatization.
\end{quote}

\section{\label{sec:11.2}Other Non-computable Problems}

Several other problems can be shown to be equivalent to the Turing halting problem; they are then non-computable. In particular, the set of undecidable problems is an infinite set that contains too many elements to be countable. Here, we discuss a few examples of problems that are undecidable. A completely computable solution does not exist for these problems. They are examples of mathematical problems that have a practical impact in our daily life; thus they show that algorithms, despite their great power, cannot solve every problem. The undecidable problems we discuss here are Post's correspondence problem, the Kolmogorov complexity of a string, Conway's Game of Life, the air travel planning problem, and the matrix mortality problem.

The Post correspondence problem (PCP) is an undecidable search problem introduced in 1946 by the Polish-born American mathematician and logician Emil L. Post, which requires deciding whether a finite set of pairs of strings of symbols has a match or not. Post proved that there exists no general algorithm capable of solving all instances of the PCP. Here is the formal definition of the PCP:

\begin{quote}
An instance of the Post correspondence problem is defined as a finite set of pairs of strings $(g_{i},h_{i})$ $(i \in [1,s])$ over alphabet $\Sigma$. A solution to this instance is a sequence of selections $i_{1}i_{2}\ldots i_{n}$ $(n \geq 1)$ such that the strings $g_{i1}g_{i2}\ldots g_{in}$ and $h_{i1}h_{i2}\ldots h_{in}$ formed by concatenation are identical.
\end{quote}

To show a simple instance of the PCP problem, we can use domino tiles as examples of couples of strings. Each domino fragment has a string at the top and a string at the bottom, like, for example, [\texttt{xz}~$|$~\texttt{xyz}]. A set \textit{S} of domino titles looks like:
\[
{S}=\{[\texttt{y}\mid\texttt{zx}\big],\
 \big[\texttt{x}\mid\texttt{xy}\big],\
 \big[\texttt{zx}\mid \texttt{x}\big],\
 \big[\texttt{xyz}\mid\texttt{z}]
 \}.
\]
A match for \textit{S} is an ordered list of one or more domino tiles from \textit{S} such that the sequence of symbols on the top is identical to the sequence of symbols on the bottom. For example, here is a match for our example set:
\[
[\texttt{x}\mid\texttt{xy}\big]\
 \big[\texttt{y}\mid\texttt{zx}\big]\
 \big[\texttt{zx}\mid\texttt{x}\big]\
 \big[\texttt{x}\mid\texttt{xy}\big]\
 \big[\texttt{xyz}\mid\texttt{z}]
\]
The top and bottom sequences of the dominos both form the string \texttt{xyzxxxyz}. Although it may seem that it should be rather easy to figure out whether a set of domino tiles has a match, a general solution for this problem is actually undecidable. That is, there is no algorithm that concludes whether any matching of Post's correspondence pairs of strings has a solution or not. Hence, there are algorithms that can solve some PCP instances but not all possible instances. This originates from the undecidability of the Turing halting problem. As we are able to reduce a Turing machine to PCP, then we can prove that PCP is also undecidable.


\looseness1In 1963, the Russian mathematician Andrey N. Kolmogorov published a paper on the computation of the complexity of producing an object such as a string of text, that is, on how to compute the length of the shortest computer program that generates the string as an output [\citealt{chap:11:Kolmogorov:1963}]. Very simply, we can say that the Kolmogorov complexity of a string \textit{x}, denoted $K(x)$, is the length of the shortest program that outputs \textit{x} given no input. For example, the shortest description of the string ``0a0a0a0a0a0a0a0a0a0a0a0a0a0a0a0a'' is ``print 0a 16 times,'' which consists of 17 characters, while the string ``01a10aa011aa0a11a010a0a1a10aaa11'' consisting of 32 characters has no simpler description other than writing a program that prints the string itself, that is, ``print 01a10aa011aa0a11a010a0a1a10aaa11,'' which consists of 38 characters. Using a function notation, the Kolmogorov complexity $K(x)$ can be defined as a function from finite strings of arbitrary length (this is specified below by the $^*$ symbol) to the natural numbers \textit{N}. Thus, for example,\vspace*{-3pt}
\[
K:\left\{0,1\right\}^*\to N,
\]
is a function defined on objects represented by binary strings of an arbitrary length. This definition can be extended to other classes of objects such as sets, numbers, probability distributions, and functions. Kolmogorov proved that no program \textit{PR} calculating a lower bound (i.e., an element of a set \textit{K} that is less than or equal to every element of its subset \textit{S}) for each string's Kolmogorov complexity can return a value essentially larger than \textit{PR}'s own length. This means that no single finite program can compute the exact Kolmogorov complexity for infinitely many texts. $K(x)$ may be supposed as the length of the shortest computer program that prints \textit{x} and then halts (see the examples above). The software program may be written in any universal programming language such as Java, C, Python, or C\#. One of the many consequences of the Kolmogorov complexity theorem in theoretical computer science is that it is not possible to implement a perfect lossless compression algorithm because there will always be strings that cannot be compressed. Other interesting applications of the Kolmogorov complexity are in the field of data compression, graph labeling, complexity of graphs and networks, and machine learning. In this last field, Kolmogorov complexity can be used, for example, for anomaly detection by comparing the complexity of a data item with the complexity of the other data items of a dataset. It is also used in model selection to measure the complexity of different learning models and select the model with the lowest complexity that best fits the input data.

\begin{figure}[!b]%\vspace*{-2pt}
\hspace*{-7pt}\tooltip{\includegraphics{graphics/Chapter_11/Figure1.\image}}{Five-step sequence of a 4$\times$4 grid of cells (some in blue, some in gray). Details are in the text before the figure.}[-330pt,3pt]
\caption{\label{fig:11.1}Five steps in the evolution of a simple Game of Life pattern.}
\end{figure}


The Game of Life (or Life) is an interesting cellular automaton proposed by the English mathematician John Horton Conway. It simulates a population of \hbox{interacting} living organisms or cells in a two-dimensional grid of square cells. Each cell can be in two states: alive (1) or dead (0). The cells change state in parallel, using a transition function that depends on its eight nearest neighbors on the grid according to the following rules:

\bgroup
\def\labelenumi{(\roman{enumi})}
\begin{enumerate}
\item A living cell can survive for the next generation if and only if it has exactly two or three living cells in its neighborhood. Otherwise, it dies.

\item A dead cell will come to life in the next generation if and only if it has exactly three living cells in its neighborhood.
\end{enumerate}
\egroup

The Game of Life gained popularity after appearing in the October 1970 issue of \textit{Scientific American} in a column written by the American popular science writer Martin Gardner called ``Mathematical Games.'' Based on the two simple rules described before, Conway built a very interesting cellular automaton that describes the evolution of a population of living organisms and demonstrates that complex phenomena may arise from very simple rules. Figure~\ref{fig:11.1} shows a simple configuration of Life composed of 16 cells in five successive steps in time. The blue cells are the live cells. At step $t= 4$, the pattern of step $t= 0$ is reconstructed in a different position (moved down to the right). This interesting property is revealed from this very simple example from Life. Moreover, using much larger configurations, it is possible to study other properties of this basic and at the same time complex cellular automaton with unique dynamics. For example, the Game of Life, like other cellular automata, shows emergence and self-organization properties. In emergent systems, global properties arise from interactions among their basic elements (i.e., the cells) although they are not made explicit in the behavior of each single element. Self-organization can be defined as the spontaneous formation of spatio-temporal patterns without external instruction. Life is a zero-player game because its evolution is determined by its initial state and no further input is required. One may then interact with it by defining an initial configuration and observing how it evolves.

The Game of Life is undecidable, and its undecidability is a corollary of the halting problem. In fact, Conway's Game of Life is theoretically equivalent to a universal Turing machine, which means that it is undecidable by reduction from the halting problem. In particular, the undecidability of the Game of Life means that given an initial pattern and a later pattern, no algorithm exists that can tell whether the later pattern is ever going to appear as an evolution of the initial pattern. Thus, there is no general algorithm for deciding the final outcome of running the Game of Life on any arbitrary pattern, except by actually simulating its running on that particular pattern. Therefore, there is no general algorithm for deciding the ultimate result of Life on an initial pattern or for deciding the halting pattern on an initial pattern.

Another interesting example of a non-computable problem is the air travel planning problem. Jeremy Wertheimer was a graduate student at MIT in the early 1990s when he visited a travel agency and was surprised at the antiquated computer program they used to search for airfares. With Carl de Marcken and other colleagues, he decided to study the problem and find a more efficient algorithm to find the best airfare for a given set of constraints. As they examined the problem, they discovered it was far harder than they imagined. As de Marcken later discovered, the airline industry's pricing system has created such a complex web of fares and associated rules that the problem of finding the cheapest airfare from airport A to airport B is unsolvable. Even when the route or the flights are fixed, the problem is non-computable. As illustrated by Carl \citet{chap:11:deMarcken:2003} in a report, given a travel query, one might summarize the air travel search problem as:

\bgroup
\def\labelenumi{(\arabic{enumi})}
\begin{enumerate}
\item guess a set of flights that satisfies a travel query;

\item guess a set of fares and a mapping from flights to fares that covers all flights exactly once;

\item guess a partitioning of the fares into priceable units; and

\item verify that all fares' rules are met, where the rules may possibly test all flights and fares in the journey but take a very restricted form.
\end{enumerate}
\egroup

The computational complexity of the air travel search problem depends on the very complex rules used by airlines. For example, rules associated with a fare used to pay for a single flight can restrict every other fare and flight included on the same ticket. These kinds of constraints make the air travel problem NP-hard, which means that the existence of an efficient algorithm to solve it would imply the existence of efficient algorithms for a whole class of intractable problems (i.e., problems without a polynomial time solution). Carl de Marcken proved that the version of the air travel search problem with no restrictions on the route or the number of stops between endpoints is undecidable; thus no algorithm designed to solve it can be guaranteed to halt with the correct answer on all inputs. Given this general unsolvability of the problem, the software systems used every day for solving the travel queries of travelers considerably restrict the problem and do not look at all the flight possibilities.

The last example of a non-computable problem we discuss is the matrix mortality problem. A matrix is a set of numbers or symbols arranged in rows and columns so as to form a rectangular table. The numbers or symbols are called the elements, or entries, of the matrix. If there are \textit{n} rows and \textit{m} columns, the matrix is said to be an ``n by m'' matrix, written ``$n \times m$''. For example, the matrix
\begin{equation*}
M=\left[\begin{array}{@{}ccc@{}}
 {5} & {0} & {-1} \\
 {-9} & {3} & {15}
 \end{array}\right]
\end{equation*}
is a matrix with two rows and three columns, which is often referred to as a ``two by three matrix.'' A matrix with \textit{n} rows and \textit{n} columns is called a square matrix of order \textit{n}. The matrix mortality problem is one of several undecidable problems involving matrices. It is a problem of determining, given a finite set of $n \times n$ matrices with integer values, whether they can be multiplied in some order, maybe with repetition, to yield the zero matrix, that is, a matrix in which all of the elements are null. More formally, the matrix mortality problem can be expressed as follows:

\begin{quote}
Given a set of $n \times n$ matrices $\{M_{1}, M_{2}, \ldots , M_{k}\}$, an integer $m \geq 1$, and some integers $i_{1},i_{2}, \ldots , i_{m} \in \{1, \ldots , k\}$, is there a product $M_{i1}M_{i2}\ldots M_{ik} = 0$?
\end{quote}

This problem is known to be decidable for two $2 \times 2$ matrices, whereas it is undecidable for a subset of $3 \times 3$ matrices and for some higher dimension matrices. This means that it is not possible to implement an algorithm that determines if a product of these matrices results in the zero matrix. Often, undecidability proofs for a mortal matrix problem are based on the undecidability of the Post correspondence problem we discussed before.

\section{\label{sec:11.3}On the Computability of Machine and Human Intelligence}

The limits of formal mathematical systems and of an arbitrary Turing machine obviously also define the limits of machine learning algorithms and AI software systems. In particular, in the field of machine intelligence, these algorithmic limits raised concerns about the possibilities of computing systems to achieve human intelligence. There have already been significant doubts about whether strong AI systems with the ability to understand or learn any intellectual task that a human being can are achievable using algorithms or standard computing machines.\break A significant number of important studies in the past 50 years have argued that G\"{o}del's incompleteness theorems defined strict bounds on the computerization of human thought, feeling, understanding, perception, common sense, and consciousness. It must also be mentioned that scientists working in different fields do not agree on what human intelligence is exactly and what components and expressions of human intelligence can or cannot be imitated through algorithmic procedures.

There is no universally accepted scientific definition of consciousness. According to the American philosopher John Searle, ``the problem of consciousness---it is a biological problem like any other, because consciousness is a biological phenomenon in exactly the same sense as digestion, growth, or photosynthesis. But unlike other problems in biology, there is a persistent series of philosophical problems that surround the problem of consciousness.'' According to \citet{chap:11:Searle:2000}. ``Consciousness consists of inner, qualitative, subjective states and processes of sentience or awareness. Consciousness, so defined, begins when we wake in the morning from a dreamless sleep---and continues until we fall asleep again, die, go into a coma or otherwise become {\textquoteleft}unconscious.{\textquoteright}'' The symposium on ``Can a Machine Be Conscious?,'' organized by the Swartz Foundation in 2001, was a milestone for the study of consciousness of robots and AI systems [\citealt{chap:11:Koch:2001}]. Some of the speakers argued that the best approach to building conscious machines is to first understand biological- and, more specifically, human-based consciousness. Most workshop participants generally agreed that any conscious machine or device would need to have a sense of self and purpose and an ability to reason about itself. It was generally believed that once a machine, such as a computer or a robot, can reason about itself and can introspect and interact in a meaningful manner with humans, the basic settings for machine consciousness would be met. A general consensus at the workshop was on the idea that one day computers and/or robots could be conscious. This thesis was based on the fact that there is no fundamental law or principle in our universe that prevents the existence of subjective feelings in machines designed or evolved by humans.

Roger Penrose, a British mathematician and Nobel Laureate in Physics, proposed a very imaginative theory to show that no Turing machine or algorithm can in principle reproduce the self-awareness feature of thought, which is a crucial element in the process of conscious understanding as experienced by humans. Penrose used a variant of Turing's halting theorem to demonstrate that a system can be deterministic without being algorithmic, that is, solvable by a computer. In his book \textit{The Emperor's New Mind: Concerning Computers, Minds, and the Laws of Physics }[\citealt{chap:11:Penrose:2016}], Penrose discusses that known laws of physics are inadequate to explain the phenomenon of consciousness and proposes new principles of physics built though a connection between classical and quantum mechanics. He is opposed to believing that the rational processes of the human mind are totally algorithmic and can therefore be reproduced by a sufficiently powerful computer. Penrose questions whether computers can become intelligent because they are deterministic machines. His thesis is that non-algorithmic processes may come into play in quantum mechanical processes, and they can be exploited by the brain. In particular, Penrose also argues that consciousness cannot be expressed in formal logic because the non-computability of the halting problem and G\"{o}del's incompleteness theorem do not allow an algorithmic logic system to emulate characteristics of human intelligence such as consciousness. The hypothesis formulated by Penrose has been criticized by physicists, mathematicians, philosophers, and computer scientists. A long-running debate arose with researchers in AI, such as Marvin \citeauthor{chap:11:Minsky:1991} [\citeyear{chap:11:Minsky:1991}], who stated ``\dots\ in my view Penrose and many other philosophers have put the problem upside down: the difficulty is not with making algorithms that can do reflection---which is easy for machines, but with consistency---which is hard for people. In summary, there is no basis for assuming that humans are consistent---no[r] is there any basic obstacle to making machines use inconsistent forms of reasoning.'' As expected, Penrose responded to the criticisms of Minsky and other scientists with other books and papers. Today, the dispute is still ongoing and surely other contributions from the scientific community will follow.

Among many other topics, Penrose wrote about the connection between consciousness and common sense because intelligence for him also needs common sense. Indeed, common sense is already a missing characteristic of AI algorithms and systems. Common sense usually refers to what people would commonly agree on, that is, everything they perceive as their shared natural understanding. More specifically, common sense can be defined as the ability to perceive, understand, and judge things that are shared by, that is, are common to, nearly all individuals and can realistically be expected of nearly all people without any doubt. Common sense, for example, suggests people check both ways before crossing the road or makes us understand that a son cannot be older than his mother. Humans are usually not conscious of the very large set of common-sense assumptions that underlie each personal declaration, opinion, or action. They tend to relate to basic and/or frequent events within human practice and are recognizable with normal human capacities. This shared and tacit background knowledge includes a general understanding of the basic principles of the world where we live, the essential human intentions and behaviors, and the awareness of very common evidence that an adult knows.

Common sense would be very useful in machine learning and data-driven machine intelligence systems. It could also be acquired through an intensive and continuous analysis of Big Data repositories of facts. However, the ability of machines to have common sense across machine learning algorithms remains very limited and highly focused on specific contexts. The lack of common sense in machine learning systems requires that those tools must be assiduously trained or instructed for every new scenario or domain where they are used. The wide unavailability or even the total absence of common sense in machine learning and AI systems prevents them from understanding the basic rules of the application domain where they operate. Therefore, those systems are often not able to understand and handle unforeseen scenarios and learn from new cases. The lack of common sense is a significant limit of current machine intelligence algorithms and systems. It must be further investigated and developed to increase AI systems' capabilities to get closer to a human-like level in the future. This should be done by designing systems that learn from data like children learn from experience and develop algorithms that imitate people's awareness for all the elements that compose the physical environment where they live.

Together with common sense, another limit of recent machine intelligence systems relates to creativity and inventiveness. AI computational models are now able to create new artwork; however, there are no current intelligent systems able to generate new ingenious or unexpected solutions or decisions. Future AI algorithms and systems should consider invention as a long-term goal for achieving strong AI results that can strengthen the ability of computational intelligence systems. Today, algorithmic systems are still not able to include and express the spontaneity of human beings and their creativity or feelings. As long as these results are not reached, natural intelligence will be considered as \hbox{irreducible} [\citealt{chap:11:Faggin:2022}] to all AI computational methods, including machine learning. Together with common sense and other human feelings, intuition is really useful in \hbox{decision-making}. Joanna F. DeFranco and Jeffrey Voas in a short paper questioned if intuition is computable, that is, if it can be expressed through algorithmic processes [\citealt{chap:11:DeFrancoandVoas:2023}]. Intuition is the ability to know or react to something without conscious thinking. It is an almost instantaneous sensation or decision that occurs without you understanding how you reached it. Scholars identified different kinds of intuition such as gut instincts like fear that are useful for survival, emotionally-based aspects of intelligence such as courage and compassion, and strategic instinct that can guide good decision-making in politics and management.

Roger Penrose discussed automation of intuition in his book \textit{The Emperor's New Mind}. He wondered if computers can be equipped with algorithms with the capability of making intuitive decisions like a human being does. In agreement with him, John Searle claimed that ``programs are neither constitutive of nor sufficient for minds.'' American philosopher Hubert Dreyfus [\citealt{chap:11:DreyfusandDreyfus:2009}] also asserted that ``Human beings have an intuitive intelligence that `reasoning' machines simply cannot match.'' Penrose also argues that algorithms cannot equal the understanding of human intuition. He claims that algorithmic processes cannot reach our intuition because this is a feature that requires solving non-computable problems for computers, problems that humans can solve. Several philosophers, mathematicians, and AI theorists, such as Marvin Minsky, Stephen Wolfram, Allen Newell, and Hebert Simon, have expressed different views on this matter. Simon defined intuition as unconscious information processing that avoids orderly sequential analysis; it is based on experience and leads to unconscious pattern recognition [\citealt{chap:11:Simon:1995}]. However, he did not think intuition ``works'' independently of analysis, but that these two components are complementary elements of effective decision-making systems.

The concept of intuition has been investigated in different fields of cognitive science, philosophy, mathematics, and computer science. However, it remains an understudied topic. Limited research work has been done on intuition-based methods in AI and machine learning. In particular, algorithmization of human intuitive processes has been difficult up to now. The main challenge comes from the fact that intuition is guided by non-logical thinking, while most of the AI models are driven by logic procedures. Indeed, AI systems have failed to express and code intuition in terms of mathematical rules because of the non-logical nature of intuition. Tests of the artificial models of human intuition have shown that implemented algorithms are not able to obtain results comparable to human intuition. One of the most difficult tasks of AI systems in intuition modeling is the unconscious nature of human intuition. The hints unseen at the layer of the conscious mind are not easily identified, formally symbolized, and stored into datasets that are used by machine learning algorithms.

A common problem in programming both common sense and intuition in machine intelligence systems is related to constructing very large and inclusive datasets collecting information about human experience. This problem is due to the immensity of human experiences and the difficulty of separating individual from collective experience. Though the collection of most of the appropriate data of past experience is achievable, a computerized model of intuition will still fail to encompass scenarios where the human mind generates very good intuitive solutions in the domains where it does not have a particular experience [\citealt{chap:11:Jolly:2011}]. Several advances have been made in modeling and implementing human intuitive processes. However, translating into algorithms the human ability to immediately perceive, process, and act upon demanding situations continues to be very difficult.

\section{\label{sec:11.4}A Few Final Remarks}

AI algorithms are very complex artifacts that involve human skills and machine learning capability. However, AI, and in particular artificial general intelligence, is not necessarily a scientific and technological endeavor to copy or replace the human mind. AI systems aim to imitate, inside computing machines, intellectual tasks that a human being can perform. We do not know if in the near or far future machine intelligence will reach human intelligence, although we must recognize that in solving some specific tasks it has done so already. In any case we know that the algorithmic processes involved in machine learning and AI tasks are not the same as what happens in the human mind---not even in computing models such as deep learning, which are based on artificial neural nets and connectionist models, are the procedures carried out by computers similar to those performed by our mind. For these and other reasons, we can say that the way computing machines ``think'' is different from the human way of thinking. In the vast majority of cases, humans are more capable than machines at finding intelligent solutions; however, in a limited number of cases AI systems are able to obtain more accurate results than humans.

For computer scientists, ``computable'' and ``algorithmic'' are often used as synonyms; therefore ``non-computable'' and ``non-algorithmic'' are also synonyms, that is, they can be used to express the same concept. A key question is if humans can act and live non-algorithmically. Actually, every day we perform tasks that seemingly cannot be expressed by an algorithm, that is, actions and relationships that cannot be carried out by a computer. American computer scientist Robert J. Marks II in his book \textit{Non-Computable You} [\citealt{chap:11:Marks:2022}] asks if it is possible to write a computer program to duplicate human pain or empathy or happiness. These are human sentiments that until now computers, even when equipped with AI \hbox{software}, are not able to express (or to compute). Apparently, they are non-algorithmic and the same holds, for example, for human creativity, pain sensation, and intuition. Computers do not experience emotion and self-consciousness. They do not have common sense. Marks reminds us that by definition and in practice, computers work using algorithms. Logically speaking, then, the existence of the non-algorithmic indicates there are limits to what computers and therefore AI systems can do.

Turing demonstrated that if a computation problem cannot be expressed as an algorithm, that is, cannot be executed by a computer, it is non-computable. Human feelings and creative actions, if they cannot be expressed by an algorithm, are non-computable, that is, are undecidable for a computing machine. On December 26, 1951, at a meeting of the American Mathematical Society at Brown University in Providence, Kurt G\"{o}del gave a lecture entitled ``Some basic theorems on the foundations of mathematics and their implications.'' In his lecture, G\"{o}del stated: ``Either mathematics is incompletable in this sense, that its evident axioms can never be comprised in a finite rule, that is to say, the human mind (even within the realm of pure mathematics) infinitely surpasses the powers of any finite machine, or else there exist absolutely unsolvable Diophantine problems of the type specified.'' Later he also added: ``If the human mind were equivalent to a finite machine, then objective mathematics not only would be incompletable in the sense of not being contained in any well-defined axiomatic system, but moreover there would exist \textit{absolutely unsolvable problems} \dots\ , where the epithet `absolutely' means that they would be undecidable, not just within some particular axiomatic system, but by any mathematical proof the mind can conceive.'' These considerations are significant for every scholar who wishes to investigate the limits of the human mind (i.e., human intelligence) and those of computing systems (i.e., machine or AI).

G\"{o}del's incompleteness theorems and the Church--Turing thesis, together with other well-established results about mathematics and automatic computing limits, cannot be directly used to give a final word about the mathematizing capacity and decision ability of human minds and how these relate to machine capability and computing power. We know that computers doing specific tasks are able to behave and produce results similar to those of humans. However, the ways in which these algorithms ``think'' are different from the ways in which humans think. As we have discussed in this book, in several tasks such as recognizing faces, playing chess, diagnosing diseases, driving cars, and others, computing systems perform similar to or better than humans. Given this scenario, we cannot make conclusive statements about the comparison between the human mind and computing machines. We prefer to quote some considerations G\"{o}del made in 1972. In a short comment included in a note titled ``A philosophical error in Turing's work'' that was not published at that time, Kurt G\"{o}del wrote: ``Turing \dots\ [in `On computable numbers'] gives an argument which is supposed to show that mental procedures cannot carry any farther than mechanical procedures. However, this argument is inconclusive, because it depends on the supposition that a finite mind is capable of only a finite number of distinguishable states. What Turing disregards completely is the fact that mind, in its use, is not static, but constantly developing. This is seen, e.g., from the infinite series of ever stronger axioms of infinity in set theory, each of which expresses a new idea or insight. \dots\ Therefore, although at each stage of the mind's development the number of its possible states is finite, there is no reason why this number should not converge to infinity in the course of its development.'' [\citealt{chap:11:Wang:1974}]

Perhaps G\"{o}del in this note did not correctly interpret some of Turing's statements about computability as prerogatives of the human mind in general. Unlike G\"{o}del, Turing did not think that the mind is something different from a very complex machine. However, both Turing and G\"{o}del agreed that the human mind is more powerful than any Turing machine. This is the fundamental challenge that they have left us and that we are facing in the twenty-first century. Indeed, machines are becoming more and more ``intelligent,'' and they are challenging human capabilities in trying to reach and surpass them. Maybe in the years to come, we will be able to find out whether the limits of machine computability coincide with the limits of human thought and action, or if the latter will always be more powerful than any complex algorithm.

\begin{thebibliography}{}
\bibitem[Davis(1973)]{chap:11:Davis:1973} M. Davis. 1973. Hilbert's tenth problem is unsolvable. \textit{Am. Math. Mon.} 80, 3, 233--269. DOI:~\href{https://doi.org/10.1080/00029890.1973.11993265}{https://{\allowbreak}doi.{\allowbreak}org/{\allowbreak}10.{\allowbreak}1080/{\allowbreak}00029890.{\allowbreak}1973.{\allowbreak}11993265}.

\bibitem[de Marcken(2003)]{chap:11:deMarcken:2003} C. de Marcken. 2003. Computational Complexity of Air Travel Planning. ITA Software.

\bibitem[\hbox{DeFranco and Voas}(2023)]{chap:11:DeFrancoandVoas:2023} J. F. DeFranco and J. Voas. January. 2023. Machining a sixth sense: Intuition. \textit{Computer} 56, 1, 14--15. DOI:~\href{https://doi.org/10.1109/MC.2022.3176694}{https://{\allowbreak}doi.{\allowbreak}org/{\allowbreak}10.{\allowbreak}1109/{\allowbreak}MC.{\allowbreak}2022.{\allowbreak}3176694}.

\bibitem[\hbox{Dreyfus and Dreyfus}(2009)]{chap:11:DreyfusandDreyfus:2009} H. L. Dreyfus and S. E. Dreyfus. 2009. Why computers may never think like people. In \textit{Readings in the Philosophy of Technology}, Vol. 89. Rowman \& Littlefield Publishers, 375--390.

\bibitem[Faggin(2022)]{chap:11:Faggin:2022} F. Faggin. 2022. \textit{Irriducibile - La coscienza, la vita, i computer e la nostra natura}. Mondadori.

\bibitem[Jolly(2011)]{chap:11:Jolly:2011} M. Jolly. 2011. \textit{The Concept of Intuition in Artificial Intelligence}. University of Lisbon.

\bibitem[Kieu(2003)]{chap:11:Kieu:2003} T. D. Kieu. 2003. Computing the non-computable. \textit{Contemp. Phys.} 44, 1, 51--71. DOI:~\href{https://doi.org/10.1080/00107510302712}{https://{\allowbreak}doi.{\allowbreak}org/{\allowbreak}10.{\allowbreak}1080/{\allowbreak}00107510302712}.

\bibitem[Koch(2001)]{chap:11:Koch:2001} C. Koch. May. 2001. \textit{Final Report of the Workshop} ``\textit{Can a Machine be Conscious}.'' The Swartz Foundation. [Online]. Retrieved February 21, 2023 from \href{http://www.theswartzfoundation.org/abstracts/2001\_summary.asp}{http://www.the{\allowbreak}swartz{\allowbreak}foundation.org/{\allowbreak}abstracts/{\allowbreak}2001\_{\allowbreak}summary.asp}.

\bibitem[Kolmogorov(1963)]{chap:11:Kolmogorov:1963} A. N. Kolmogorov. 1963. On tables of random numbers. \textit{Sankhy\={a} Ser. A.} 25, 369--375.

\bibitem[Marks II(2022)]{chap:11:Marks:2022} R. J. Marks II. 2022. \textit{Non-Computable You: What You Do That Artificial Intelligence Never Will}. Discovery Institute Press, Seattle.

\bibitem[Martin(1958)]{chap:11:Martin:1958} D. Martin. 1958. \textit{Computability and Unsolvability}. McGraw-Hill, New York.

\bibitem[Minsky(1991)]{chap:11:Minsky:1991} M. Minsky. 1991. Conscious machines. In \textit{Machinery of Consciousness, Proceedings of the 75th Anniversary Symposium on Science in Society}. National Research Council of Canada.

\bibitem[Penrose(2016)]{chap:11:Penrose:2016} R. Penrose. 2016. \textit{The Emperor's New Mind: Concerning Computers, Minds and the Laws of Physics}. Oxford University Press.

\bibitem[Searle(2000)]{chap:11:Searle:2000} J. R. Searle. 2000. Consciousness. \textit{Ann. Rev. Neurosci.} 23, 1, 557--578. DOI:~\href{https://doi.org/10.1146/annurev.neuro.23.1.557}{https://{\allowbreak}doi.{\allowbreak}org/{\allowbreak}10.{\allowbreak}1146/{\allowbreak}annurev.{\allowbreak}neuro.{\allowbreak}23.{\allowbreak}1.557}.

\bibitem[Simon(1995)]{chap:11:Simon:1995} H. A. Simon. 1995. Explaining the ineffable: AI on the topics of intuition, insight and inspiration. In \textit{Proceedings of the 14th International Joint Conference on Artificial Intelligence}, Vol. 1. Morgan Kaufmann, 939--948.

\bibitem[Wang(1974)]{chap:11:Wang:1974} H. Wang. 1974. \textit{From Mathematics to Philosophy}. Routledge, London.
\end{thebibliography}

%\end{document}

