%\documentclass{acm-book-v2}
%\RequirePackage[errorshow]{tracefnt}
%%\newcommand{\mpage}[1]{}
%%\newcommand{\indexfn}[1]{}

%%\usepackage{showframe}

%\usepackage{custom-tooltip}
%\usepackage{custom-tooltip-Alt-Text-View}



%\begin{document}


\setcounter{chapter}{7}

\chapter{\label{chap:8}Algorithms and Politics}


\noindent The role and influence of algorithms involve large communities of people and affect the dynamics of political and social organizations. This chapter analyzes the role of algorithms in changing political parties and influencing political decisions and the wellbeing of democracy. How do Facebook or Twitter algorithms work to increase social engagement? How are digital platforms managed to support or contrast political decisions? How are relationships among leaders and citizens changing due to algorithms? These are some of the questions addressed in the chapter, together with a discussion of important concepts such as cultural hegemony of algorithms and their role as regulators of people's daily lives.

\section{\label{sec:8.1}Algorithms, Information, and Democracy}

Algorithms are automated decision makers programmed to solve problems, manage tasks, organize processes, interact with people and machines, and process data in computers and on the Internet. In performing these roles, algorithms influence many aspects of our societies; consequently, they serve a political function and exercise a new form of power. In the previous century, science and technology generated innovations that have had a wide social impact and played key roles in social transformation. Among these innovations, digital technologies have shown considerable ability to transform the world and for this reason they also have assumed a significant political role. The notable and deep impact of computing systems on our lives has moved decision-making from the traditional meeting rooms of politics to the board rooms of big tech companies. Because of the algorithms they design and the AI systems they produce, the technical leaders of digital firms, the developers of widely used software apps, and the owners of the most innovative big companies in the world exert a political influence greater than that of premiers, chancellors, ministers, or parliament members. A few CEOs of big techs or some brilliant young \textit{startuppers} often decide the times and the ways of introducing innovative products or services that can change our way of life, while politicians are often unable to influence this innovation process and prevent potential negative impacts on citizens.

Myriad algorithms running inside the apps and the digital services we use every day influence our choices, shape our private and public relations, and partly guide our cultural and political beliefs. Among them, we should consider the algorithms used by social media platforms that organize and disseminate public news and personal information according to strategies that are often not clear and cannot be controlled by users. Social media has replaced traditional media as the most effective and impactful vehicle for spreading information. The pervasiveness and the personalization of content ready for use through mobile devices have assumed a considerable role despite the large number of inaccuracies, problems they engender, manipulations, and information construction that social media permit.

Billions of individuals are informed and inform others through social media such as Facebook, Twitter, Instagram, Telegram, and TikTok, finding new ways of communication that were not possible before. As a result, television channels are forced to mention and diffuse news and events that originated from social media. This new information space has taken a central role in the information and communication universe. It is a digital space where anyone may say something to the world. To play an active role in this infosphere, many people provide content that is accurate and instantaneous while others post imprecise, wrong, or improper information that can misinform. Fake news is the most evident example of this way of thinking. Posts may consist of deliberate disinformation or hoaxes mainly spread via social media, although they often reach traditional media such as radio, television, and newspapers. The relevance and the danger created by fake news has increased in post-truth politics where it is more important that an item of news circulate on the web rather than the truth.

We don't know all the details of how algorithms of social media platforms such as Facebook and Twitter work, how they decide what to show (and what not to show) users. However, we know some technical details that can be discussed. The Facebook machine learning algorithm is composed of four main elements:

\begin{enumerate}
\item[(i)] The \textit{inventory of stories}: this refers to all the content found on the platform. It is any stock displayed to a user on their feed, including posts from family, close friends, Facebook pages a user has liked, and groups a user may have joined.
\item[(ii)] The \textit{signals}: actions that encourage engagement, including likes, comments, replies, and shares. Also, posting time (recency), view time, and story type are signals used to inform ranking decisions.
\item[(iii)] The \textit{predictions}: these are based on a profiling algorithm that analyzes a user's behavior and how they interact with or react to a specific post.\break The machine learning algorithm used for behavior prediction considers what a user has been searching online and the posts they have been responding to in order to display content they may be interested in.
\item[(iv)] The \textit{relevancy score}: this depends on the likelihood that a user will react positively. This score is different for every user. The higher the relevancy score, the higher the chances that the post will be displayed at the top of the user's feed.
\end{enumerate}

The first version of the algorithm developed in 2009 did not include these elements, and it was very simple as it ranked posts based on the likes they received. Posts with the most likes were put on the top of the feed. After a few years, the Facebook team working on the recommendation algorithm implemented new versions based on machine learning techniques for prioritizing posts. For example, in 2016 a ``time spent'' ranking signal was added to measure a post's value based on the amount of time users spent with it, even if they didn't like it. In 2017, Facebook introduced weighing reactions, and the ``completion rate'' signal was added for videos. Videos that keep people watching to the end are shown to more people. In 2018, a new version of the algorithm prioritized ``posts that spark conversations and meaningful interactions,'' it also started bumping up content that people engage with the most (``close friends''). Finally, in 2020 the algorithm started to assess the reliability and value of news articles for promoting substantiated news rather than misinformation. This is a critical issue that has also been addressed in the new version of the Facebook algorithm developed in 2022 and 2023.

Like the first algorithm of Facebook, Twitter's feed in 2006 was also structured to show tweets in reverse time order. Later, to increase user engagement, Twitter implemented a more complex sorting algorithm based on data analysis to rank tweets, promoting the ones people are more likely to see. The current Twitter ranking algorithm (it is constantly changing) is based on machine learning techniques that, like the algorithms of other social media platforms, exploit a wide set of factors including engagement (likes, retweets, and replies), timeliness, and the user's profile built by tracking the accounts they follow and the types of content they interact with on Twitter. Twitter also uses machine learning to suggest new accounts for users to follow. The algorithm looks at factors such as the kinds of content the user engages with, who the user already follows, and who the user's friends are following. Additionally, Twitter uses machine learning techniques to generate better search results for specific topics or events. For example, during a major cultural event, Twitter algorithms are run to cover the most relevant tweets and content related to that event. Despite their complexity, Twitter's algorithms sometimes produce ``strange'' results that can harm users, produce disinformation, or negatively influence people's decisions. For these reasons, in 2021 Twitter set up a Machine Learning Ethics, Transparency, and Accountability (META) team, a group of programmers, researchers, and data scientists working to assess downstream or unintentional harms in the algorithms. In November 2022, when Elon Musk bought Twitter, the team was dissolved, although it was well-respected for its exploratory work in ethical AI and algorithmic transparency. Indeed, the team's goal was to promote responsible use of machine learning solutions in Twitter, providing a fairness assessment of Twitter timeline recommendations across racial subgroups and the analysis of content recommendations for different political ideologies across countries. The creation of this team shows the importance of social media content delivery, signals its political impact, and warns us about the need for transparent machine learning systems.

Social media together with the Internet that provides their networking infrastructure, implement a multi-centric, interactive, cooperative, and dialogic space for content delivery. The structure, connection model, people relationships, and content delivery of social media platforms are defined by their complex algorithms. Their choices can influence the way people are informed, and can manipulate the opinions of citizens or advance the know-how of individuals. As the dissemination of content that continuously occurs on social media platforms contributes to defining a large part of the public debate, it is evident that the algorithms that select the strategy of dissemination and interaction of posts, tweets, stories, and short videos play a political role in the societies of the new millennium. Flexibility of algorithms allows social media to continuously open spaces for information, discussion, and dialectic conflicts that old media cannot implement and offer due to their intrinsic limits and static nature. Online, each individual can express their opinion; however, sometimes people can also do this inappropriately or deliberately produce misinformation or disinformation. Citizens can comment and interact with other people, involving not only their friends and colleagues but also unknown people with whom they share an interest or with whom they clash with remotely. This social model supported by algorithms does not guarantee a better practice of democracy. It does not eliminate the falsification of information, rather it facilitates individual falsifications. However, the assumption remains that the digital space is elastic, open, flexible, and may offer forms of direct democracy supported by software systems.

\section{\label{sec:8.2}Digitalization of Politics}

Among the many deep transformations that the massive use of digital technologies is producing in our society, a very relevant one is what we could generically define as the ``digitalization of politics.'' The new digital technologies, through their complex algorithms, large amounts of Big Data, and instantaneous and pervasive communication, have been having a strong influence on political parties, their media, political discourse, and citizens' involvement. In other words, they are influencing the rules and functioning of democracy. In fact, the many digital services offered via the Internet have changed the ways in which citizens define and share their political opinions and the ways in which they interact with each other, their representatives, and with public administrators. The web, social media, and the massive use of digital devices have changed people's relationship with politics, the organization of the State, and the exercise of power in the digital age. This relationship is increasingly mediated by software systems (mobile apps, chatbots, opinion mining, and sentiment analysis algorithms), which determine the forms of dissemination of news, interaction between political parties and their potential voters, orientation of public opinion, and collection of consent. We know, for example, that autocrats use social media to control political discourse and influence elections. For example, social media communications played a noteworthy role in the 2022 Philippine presidential elections. The production and dissemination of election-related information through social media resulted in influenced polarization and mobilization of Filipino voters in the elections. Disinformation narratives of conspiracy theory, democratic disenchantment, and strongman leadership fueled support for Ferdinand Marcos Jr. and undermined the other candidates. At the same time, ex-President Rodrigo Duterte hired hundreds of people to distort online information and discourse during the electoral campaign. Similar cases occurred in Russia where social media have been used to misinform its own population and also to launch disinformation campaigns in other countries including the United States, Germany, Ukraine, France, and Italy.

Indeed, in the world of politics there are different approaches and different trends in the relationship and use of digital technologies. The most recent political movements such as Podemos in Spain, Pirate Parties in Belgium, and the Five Star Movement in Italy have embraced digital platforms with conviction by linking them to the hitherto unfulfilled desire to build forms of direct democracy. Other parties have tried to ride digital systems for propaganda purposes while the more traditional parties struggle in their relationship with digital media and suffer significant delays in its understanding and use. Unfortunately, most citizens find it hard to recognize that the impact of digital tools on political participation is a crucial issue and not just a topic of discussion among specialists. Instead, it is necessary to adequately reflect on this question that is becoming more and more important every day for the life of democratic countries and also for the role it plays in totalitarian regimes. What has been happening since the beginning of the 21st century in many nations of the world clearly indicates how the effects of digital technology on politics, both in democratic and dictatorial systems, are much greater than what politicians themselves seem to perceive. Today, thanks to digital technologies, the communication and sharing of every choice, every statement, and every action by a party or one of its representatives reaches everyone instantly, creating moods and reactions that previously took much longer to disseminate. Many politicians are unable to adapt to this digital immediacy and only those who understand that the use of the digital medium requires new ways of experiencing the public space are able to take advantage of it. Others are often overwhelmed by it or make embarrassing gaffes. Added to this is the enormous distortion of citizen participation in political life that is continually put into practice by the spread of fake news, which distorts reality and shifts the debate from real issues to artificially constructed ones. In this sense, an ecological use of digital communication and political strategies based on AI systems is highly desirable.

However, the ease of access and communication offered to all by the digital space has given many the impression and illusion that everyone can act to influence political power, that anyone can help write laws; in short, anyone can influence the functioning of the State with their digital presence, tweets, posts, or their social avatar. This is a scenario that we can define as \textit{digital populism}, where the individualism of everyone is exhibited, however immersed in the great atomized flow that operates a new disarticulation of political opinion that was traditionally organized and conveyed in structured political forms. While this is the trend of a large part of the digital masses, it should be noted that there is also a limited diffusion of digital tools and platforms for the orderly and reliable collection of citizens' and/or party supporters' opinions on specific problems and issues. Unfortunately, the digitalization of politics has seen numerous and continuous attempts to manipulate information and many propaganda actions; it also offers few digital places for real consultation, listening, and moderate debate. Democratic parties and governments have contributed very little to proposing, financing, and implementing public digital platforms for real political participation. Yet, technology would easily allow it and some examples prove it. Two examples of platforms for political participation are DemocraciaOS, a free software developed in Argentina to increase public participation in political decision-making, and Code for America, an open-source technology and networks association to make government services accessible, effective, and easy to use for US citizens. Some survey studies [\citealt{chap:8:SantiniandCarvalho:2019}] have observed that most of the available software platforms for citizen participation are governmental initiatives that foster a top-down information flow with some possibility for interaction and discussion between citizens and governors but very limited or no influence on the political decision-making\vadjust{\vspace*{-18pt}\pagebreak} process.

Information overload generates disinformation. The availability of an almost infinite mass of information, instead of supporting informed and conscious choices, confuses people and enables them to be manipulated. The management of the public sphere through digital tools offers the possibility of creating new and very positive experiences, but this frequently does not happen due to the lack of knowledge of the nature and potential of digital technologies by political parties and by most of their advocates, thus allowing coarse, direct, but ineffective communication methods to prevail. The ``tool recalcitrance'' outlined by American sociologist Philip \citet{chap:8:Selznick:1957} signals to us that the tools often tend to modify ends and push for a life of their own by hindering changes. McLuhan's well-known phrase, ``The medium is the message,'' is still valid and reminds us that since the medium shapes the content, one cannot venture into the digital universe without knowing it and thus risking having one's message distorted by politics. The new space created by digital technology is a fundamental resource for politics, but this only becomes true if the conceptual and expressive knowledge of that space is combined with appropriate use to communicate clear and innovative political proposals. Along with the positive aspects, the great potential offered today by the digital world is impoverished by an uncertain, sometimes manipulative and other times undemocratic use of digital tools and platforms. The historic events related to the assault on the United States Congress in January 2021 have shown what extreme forms of politics conveyed and manipulated through social media can beget. At the same time, they have shown how large digital companies can implement large-scale communication boycott operations by depriving a US President (albeit defeated) of any social space. An investigation by \textit{ProPublica} and \textit{The Washington Post} conducted in 2022 found evidence that Facebook played a ``critical role in spreading lies that fomented the violence of January 6.'' Approximately 650,000 posts in Facebook groups attacked the legitimacy of Joe Biden's presidential victory over Donald Trump and many called for political violence. President Biden criticized former President Trump for his incitement on social media: ``The former president of the United States of America has created and spread a web of lies about the 2020 election.'' Trump's indefinite suspension from Facebook and Twitter, where he had, respectively, around 35 and 89 million followers, was the result of this unprecedented political scenario where software platforms played a key role.

Like other digital spaces, we must consider that social media platforms were created by private individuals or companies for profit, not for supporting democracies. At the same time, ad hoc platforms created by parties---examples of which are the Rousseau platform used by the Five Star Movement in Italy, the LiquidFeedback system of the Pirates, and the Podemos' Participa portal---have so far proved to be ineffective because they are not really\vadjust{\vspace*{-17pt}\pagebreak} democratic. Their control is in the hands of a few people and their operating logics are opaque. While these platforms were presented as tools to reduce or eliminate the role of intermediaries in making political decisions, and encouraging direct involvement by members, their practice has been plebiscitary and top-down. The real contribution of members has been limited as they are only called to stamp their approval on decisions previously made at the top. This gloomy scenario indicates the need to formulate and implement new digital models for politics that are defined by communities and governed by democratic laws. The large-scale public debate on digital platforms has not worked so far and continues to generate breakdowns and manipulations. For this reason, new tools and public digital platforms are needed that can facilitate democracy, bring parties to life, or determine their replacement if this will be useful for society.

\section{\label{sec:8.3}Algorithmic Hegemony}

In 2022, four of the top five largest companies in the world by market capitalization were digital tech companies. The Saudi Arabian Oil Company (Saudi Aramco) was the exception, while Apple was the world's largest company and the other three were Microsoft, Alphabet (Google's parent company), and Amazon. The digital empires built by these companies are based mainly on algorithms. They were founded on innovative and original software systems that have been able to attract billions of clients worldwide and achieved a leading role worldwide. To reach this dominant position, algorithms first assumed a leading role in our society and are subsequently exercising their acquired operational and cultural hegemony to practice a new kind of power, an original form of supremacy based on pervasive automated procedures.

The scientific and cultural impact of digital technologies is generating a new form of cultural hegemony capable of also acting at a political level through a process of generalized consensus that is able to guide the behaviors, mentality, and relationships between individuals. We are witnessing an extra-technological phenomenon induced by technical--scientific progress that can be described through a new form of cultural hegemony that receives enormous consensus, which without great difficulty can be translated into a new form of domination in the future. Thus, we can speak of an ``algorithmic hegemony'' that can be seen as the most recent evolution of the cultural hegemony that was analyzed about a century ago by the Italian philosopher Antonio Gramsci. This evolution is planetary in nature and therefore does not spare any nation even if it has different social and political effects in each. While in authoritarian States it serves to strengthen power to the point of allowing for a more impalpable but extremely invasive exercise, in democracies it can push toward forms of post-democratic ``algocracies'' in which the logics codified in the algorithms can become the new practices, if not the new rules to regulate everyday life.

The concept of hegemony was born in ancient Greece and important traces of it can be found in the writings of Herodotus, Thucydides, and Xenophon. It was used to indicate the leadership and preeminence of a city-state within an alliance---for example, Sparta led the military actions of the Peloponnesian League (Spartan hegemony) and Athens of the Delio-Attic League (Athenian hegemony). A hegemonic State could decide how its League should act but could not violate the autonomy of the allied States or deal with the internal affairs of each State. Thus, hegemony was a guide and not a domain. The main context for the term has been military, but it has also been used to describe the political relations between States in which relations of parity or preeminence are described in terms of balance or hegemony---indicating in the latter case the alteration of balance to the advantage of one side or the other. In fact, if in ancient Greece hegemony found dynamic applications resulting from the continuous tensions between the various city-states, the Roman Empire is perhaps the first case of a stable and vast affirmation of that concept that was born some centuries earlier and which the Romans practiced without naming it. In fact, Latin does not have an equivalent word for hegemony, while using the term \textit{imperium} extensively. In the modern era, the usage of the concept of hegemony was revived around the mid-19th century. From \hbox{German} and French political literature---Immanuel Wallerstein used it, for example, in an economic context demonstrating that the concept is useful for explaining different situations---it arrived in Italy. Toward the end of the 1920s, while in prison, Antonio Gramsci worked around this concept by elaborating an original theory of cultural hegemony that is still used today worldwide to explain political, social, economic, and even scientific hegemony. In fact, \citeauthor{chap:8:Gramsci:2011} [\citeyear{chap:8:Gramsci:2011}] in the \textit{Prison Notebooks} wrote on cultural hegemony to apply it to the analysis of the construction of political power within a modern State.

Cultural hegemony indicates that, through the ability to direct the vision of the world and the life of the masses, the leading groups establish guiding relationships. Hegemony thus becomes a form of power based on consensus that makes it possible to gain, through persuasion, adherence to a political and cultural project. In this conception, a position of hegemony is achieved when a group establishes a social order that combines leadership and power, coercion and consent. Hegemonic practice is more sophisticated than propaganda and imposition and is more effective than consensus. For these reasons, the process of building hegemony is a fundamental tool in the construction and affirmation of power in technologically advanced societies. What is happening now is that the exponential diffusion of digital technologies has created a new form of cultural hegemony that has \hbox{produced} a new supremacy based on consensus. An original form of consensus of an enormous mass of individuals who, through automatic tools based on ``intelligent'' algorithms, are expressing widespread adherence to a cultural and political project that combines a massive amount of data and algorithms to govern the processes that make the world ``work.'' A consensus that is imposing a vision of the world defined by a ruling class with a strong technological footprint. A new and particular materialization of that cognitive elite was described by \citeauthor{chap:8:HerrnsteinandMurray:1994} [\citeyear{chap:8:HerrnsteinandMurray:1994}] in an essay written at the end of the last century. The hypothesis of the two American scholars is based on putting into practice the high intelligence of some people who by their nature are capable of better and more comfortable lives and who can express the ability to guide society. Their theory is also based on the technological elements that play an important role in our societies. That theory has received criticisms, but now the novelty is the transformation of the talent and intelligence of this new cognitive elite with a strong technological imprint into algorithms that they help to design, implement, and commercialize on a vast scale. Talent turns into algorithms, and algorithms give shape to the software applications that hundreds of millions or billions of people use every day. Talent is then transferred to computers and all digital devices, and through them it guides large masses of individuals. In some cases, it also manipulates them for loyalty and profit purposes. It is therefore ``materialized intelligence'' that operates, mediates, organizes, influences, spreads, and guides, taking the form of algorithmic processes, large social bodies in a hegemonic process in which the algorithm materializes and implements the intellectual capacities of a ruling class.

The modern and simplified declination of Gramsci's cultural hegemony is also expressed by the concept of soft power introduced by Joseph \citet{chap:8:Nye:2009}, an American professor and former dean of the Harvard Kennedy School of Government. In introducing the soft power concept, Nye drew inspiration from Gramsci. Nye's idea was to propose a light but effective form of power through initiatives useful for persuading, convincing, and attracting individuals toward the ideals and lifestyles of a nation. The arts, economic well-being, free information, and the wealth of commercial products are some examples of elements that can contribute to the exercise of soft power. Indeed, this concept is a simplification of cultural hegemony in the Gramscian sense because it does not include the processes of construction of cultural hegemony as imagined by Gramsci. However, the influence of the digital world can be traced in some respects to the soft power that the United States, according to Nye, had to exercise over the rest of the world to be hegemonic. \hbox{Certainly,} in recent decades the development of digital technologies has been widely used as a form of exercise of soft power to build forms of political and economic supremacy that with a lexical extension we could define as software power\vadjust{\vspace*{-18pt}\pagebreak}.

To conclude the discourse on algorithmic hegemony, it is appropriate to mention a further element of innovation that many today do not think about, and which resides in the possibility that the cultural hegemony exercised by the cognitive elite, as owners of the mass production of algorithms, may one day be transferred to the algorithms themselves. In the future, algorithms could become capable of operational autonomy, that is, capable of making choices and behaviors that are technically called \textit{autonomic}. New decisions and operations could be implemented by the algorithms themselves with the help of the digital machines that they govern, thus enabling them to take the form of a new algorithmic ruling class capable of exercising enormous power over human beings without having the need to be guided by them. Autonomic computing has been inspired by biological systems such as the human autonomic nervous system. It is a computing paradigm that was born with the aim of providing computers with the techniques and hardware--software tools necessary to manage themselves without human intervention [\citealt{chap:8:ParasharandHariri:2007}]. Autonomic software systems are designed and implemented through algorithms capable of making choices and decisions autonomously (without the intervention of a human user). They are based on computational strategies programmed to analyze a set of input data and environmental conditions and adapt their behavior according to the acquired information and the status of the analyzed context. Autonomic computing systems were introduced by IBM for hardware--software system maintenance (e.g., pre-failure notification, automated device backup and recovery, memory error correction, and automatic software upgrading); however, they are used in several application fields, for example in finance, inventory management, pricing policies adaptation, and customer relationship management. With advances in machine learning and AI, autonomic computing solutions may embody new adaptive algorithms that allow them to become successful in handling very complex tasks with very limited or no human intervention.

\section{\label{sec:8.4}Marcuse and the Digital Man}

In 1964, the German-American philosopher Herbert \citeauthor{chap:8:Marcuse:1964} [\citeyear{chap:8:Marcuse:1964}] published \textit{One-Dimensional Man: Studies in the Ideology of Advanced Industrial Society}, which was recognized as one of the most important books of the 1960s. In his book, Marcuse supported the thesis that the social order dictated by advanced industrialization, generated and favored by technology and the spasmodic capitalist pursuit of profit, had by now influenced and transformed all aspects of human existence. In Marcuse's idea, the ``rational'' model of industrial capitalism has reduced the life of the individual essentially to the need to produce and consume without leaving room for forms of dissent, free thought, and resistance to\vadjust{\vspace*{-16pt}\pagebreak} established power. In the early 1960s, Marcuse wrote, ``In this society [advanced industrial society], the productive apparatus tends to become totalitarian to the extent to which it determines not only the socially needed occupations, skills, and attitudes, but also individual needs and aspirations.'' Then he added: ``Technology serves to institute new, more effective, and more pleasant forms of social control and social cohesion.'' This last sentence is today more true than ever, and the described scenario is accomplished thanks to the key role of the extraordinary, advanced technologies produced by humans, of which digital technologies and genetic engineering are the most established \textit{avant-garde}. It is sufficient to think of the many sophisticated forms of personal and social control that digital technologies have brought into play today together with the latitude these pleasant new forms of social cohesion such as the Internet, social media, and online meeting tools offer to all.

After that prophetic beginning, Marcuse in the \textit{One-Dimensional Man} continued his analysis of the role of technological innovations, emphasizing how they shape ``the entire universe of discourse and action, intellectual and material culture. In the medium of technology, culture, politics, and the economy merge into an omnipresent system which swallows up or repulses all alternatives.'' He then adds an ever more topical truth: ``Technological rationality has become political rationality.''; ``The techniques of industrialization are political techniques; as such, they prejudge the possibilities of Reason and Liberty.'' It is increasingly true today that science and its technological implementations profess their independence above all with respect to politics and the economy, pushing companies in a certain direction without the need or constraint of having to ask or wait for a democratic endorsement. The power of science and technology does not come from consensus but from the ability to explain, in terms of practical validity and of effectiveness. The one-dimensionality of the man that populates advanced industrialized societies is therefore for Marcuse a status determined by economic and profit choices that find their most efficient mechanisms in advanced technologies.

After more than half a century, we can certainly acknowledge the validity of Marcuse's theories, above all in relation to the very wide use of information and communication technologies and their role as regulators of every moment of people's daily lives. Digital systems have consolidated and expanded the diffusion of that human one-dimensionality that Marcuse described in 1964 in a different context from the current one, but not entirely irrelevantly to our present. The German-born philosopher had well foreseen how (digital) technologies were capable of shaping human material reality and thought, thus forcing everyone to deal with a medium governed by a few and which for the most part currently responds to the logic of profit and not of liberation. Digital technologies do this not by their intrinsic nature but because they have precisely become political technologies that serve the production system that generated them. Indeed, the use of digital technology forced by the large IT companies pushes toward the transformation of society into a fully administered and automatically regulated universe. The risk that has largely already found its realization is that humans are daily pushed toward that Marcusian one-dimensionality that provides/obliges knowing the elementary use of the automatic operating mechanisms (and of the devices that implement them), which guarantee, or even constitute, the relationships between individuals and therefore the operational functioning of society. This requires the model that increasingly implements the calculating/calculable industrial/algorithmic/robotic society fully reached in the new century.

Advanced technologies and their uses give individuals the impression of offering all the same possibilities of action and therefore acting as shock absorbers of social conflicts. They appear popular and egalitarian, while in fact they are regulators, controllers. They allow everybody to express their opinion in a sort of instantaneous cybernetic populism. However, the effect desired by the person expressing the opinion is drowned in a gigantic digital container that in a very short time homogenizes and pulverizes it together with millions of other opinions without allowing the emergence of the best ones, indeed favoring the worst, the most fake, the most banal. On every occasion that we act using digital machines to solve our problems, to carry out our work, to simplify our lives, all useful and necessary actions that we can no longer carry out without computers and their algorithms, we discover that we cannot live without the help of these technologies. We become flattened out by machines and their internal logics because it is we who depend more and more on machines and not them on us, even if we are the ones who created, spread, and fed them. Algorithms, apps, Big Data, and web portals that relentlessly deliver goods and services are the operational arms of the gigantic digital platforms that act as managers and administrators of the lives of a large part of mankind. Mankind in the 21st century risks becoming secondary to the great digital machine in which it is immersed. A humanity operationally enhanced by its digital prostheses but which, at the same time, becomes antiquated (as Gunther \citeauthor{chap:8:Anders:2002} [\citeyear{chap:8:Anders:2002}] had well described in his book) thanks to the power and perfection of the artificial devices he has created. A humanity that has the freedom to choose among a few smartphone models, among a few operating systems, among very few Internet service providers, among perhaps ``about two'' e-commerce giants from which to stock up on all consumer goods, using these tools not only to do better and more but also to avoid doing so many normal things that it once did without digital devices and which it now leaves entirely to the machines.

Herbert Marcuse passed away in 1979, when the Internet, the web, social media, AI, and other computing technologies had not assumed the fundamental role in our lives that they have today. However, his analysis of the relationship between industrialized society, technology, and human beings still shows all its relevance and is a very useful tool for understanding how the functionality and pervasiveness of digital technologies are pushing toward the human one-dimensionality that he had perfectly described. The parasitical needs that Marcuse identified as products of the consumer society still present themselves today as contrary to real needs that, if satisfied, can make the world better. Parasitical and alienated functions are today undoubtedly amplified by the products of digital technologies which from facilitating agents become doping substances that often pull people away from their real needs. Marcuse did not contest technology per se, but the economic and political abuse that the society he explored made of technology. Similarly, today it is not useful to contest the solutions that digital technologies offer but their many discriminating practices, the pressure toward totalitarian rationalism, and the abuses that are stimulated and implemented for profit and/or domination purposes. Science can and must possess a critical capacity toward the use of technology (of its technological products) to make it freer and at the service of freer people.

\section{\label{sec:8.5}Political Influence}

The processes of guidance, orientation, and domination have been amplified by web portals, smartphones, user profiling algorithms, and social media that are increasingly tools for the exercise of hegemony by the large digital companies that spread content in the world and at the same time acquire data on their frequently unwitting users for a use that is not always ethically acceptable. To exercise an apparently ``soft'' power that becomes extremely pervasive and influential. Max \citeauthor{chap:8:Weber:2019} [\citeyear{chap:8:Weber:2019}], the German sociologist and political economist best known for his work on the relationship between Protestantism and capitalism, clearly explained how power is the ability to exercise control over the behavior of others even without their consent, influencing their decisions. This definition is appropriate and explains very well how an algorithm today is a form of power that is exercised through automatic control over individuals (over what they do on the Internet, their online relationships, the work they do using computers, and much more). Along with control, algorithms also exercise conditioning through the choices that have been programmed into the many algorithms that are widely used and that many know only superficially. They are active elements that allow those who design them, those who implement them, and those who sell and disseminate them to exercise authority.

As we have discussed, developing an algorithm means defining a series (a few tens or many tens of thousands) of operating steps (instructions) that, when coded in a programming language, become a software program that will be executed every time a user taps the program icon or it is run by another program. Every time that code is executed, the operational power of the algorithm imposes itself. Often, it is a positive power that is used to solve problems, to calculate results, to produce useful information. Other times it is a harmful power that decides for those who use it and forces individuals to conform to its decisions. Every time someone says ``The computer decided it,'' this confirms an algorithmic authority that almost no one can challenge and only a few specialists can understand. Our daily lives are programmed (in a pleasant way) by the algorithms of our smartphones, by those that control the functioning of the Internet and social media platforms. In this latter case, it is our sociality that is programmed, not by us, not by the people we meet at home, on the street, or at work, but by machines and their algorithms that propose, support, or diminish human relationships mediated by the code and Big Data. Our social relationships are dominated by platforms full of algorithms such as Facebook, Twitter, Instagram, TikTok, Snapchat, Telegram, WeChat, and Flickr. The algorithms of these ``digital nations'' put us in touch with Tom rather than Dick. They present us with information based on the choices that programmers make in Silicon Valley, China, or Singapore and condition our day on the basis of choices that we do not govern and very often we do not even know about.

Yet, most of the users of these platforms (billions of people) welcome the content that is offered to them. They welcome the suggestions of ``new friends'' and new daily digital relationships. The Internet, the web, social media, and apps combine in a more invasive and continuous way than the old mass media of the last century, building a global ecosystem in which billions of individuals live at the dawn of the third millennium. It is together and within these lightweight but powerful algorithmic machines that the great majority of the world's population forms its culture, its vision of the world, its scales of priorities, and its ability to analyze reality. These are the algorithms that condition our desire for information by selecting for us the news to read on social networks or on the web. These are the algorithms that suggest this or that restaurant, this or that hotel. These are the algorithms that collect our every keystroke to make it a signal of potential interest and transform it into advertising information that also pursues us from one device to another, relentlessly. The power of mediation, which in modern democracies has been firmly in the hands of the political class for a long time, is now increasingly being transferred to the hands of those who own and manage digital platforms. Big tech companies collect data about people, information, facts, and events and predict and guide voter behavior to the same extent as consumers. They do so with extremely dangerous effects for the governance of democratic societies. The cases of Cambridge Analytica, Russian bots, and the widespread Social Credit System in China that we will discuss in the next chapter are some well-known examples of a wider phenomenon based on the manipulation of reality through Big Data and algorithms that will become capable of putting democracies and freedom of thought and action in peril.

Among thousands of examples is the investigation by researchers at the watchdog group Global Witness and New York University's Cybersecurity for Democracy (C4D) of Facebook's AI moderation system in the run-up to the US midterm elections. On the day of or the day before the 2022 US elections, the researchers submitted ads that had explicit intimidation content against election workers and violated Meta, TikTok, and Google's ad policies. Facebook argues that it prohibits content that threatens serious violence; however, the test showed that 15 of the 20 ads containing violent content were approved. The researchers noted that the same ads were all rejected by YouTube and TikTok and the accounts associated with them were suspended. Researchers declared that ``The fact that YouTube and TikTok managed to detect the death threats and suspend our account, whereas Facebook permitted the majority of the ads to be published, shows that what we are asking is technically possible.''

Moving from social media to search engines, it is worth mentioning the work by Robert Epstein and Ronald Robertson. Epstein and Robertson are two scholars of the American Institute for Behavioral Research and Technology who have carried out research on the conditioning that voters who do not have a good knowledge of the candidates of an electoral competition can receive from search engines and how these choose and present the web pages that talk about the candidates [\citealt{chap:8:EpsteinandRobertson:2015}]. In the experiments, they showed how the sequence of results presented by a search engine on some candidates can influence the vote of the citizens who viewed them. In one of these tests, providing a list of sites that contained information on candidates who were not well known by the voters, it was found that the latter saw more favorably the candidates who were shown in the first positions in the results proposed by the search engine and for this reason voters were more willing to vote for them. Epstein and Robertson measured how citizens' voting preferences can be conditioned by the order provided by a search engine from a minimum of 20\% up to a maximum of 80\%. The highest influence rates are for voters who have little political interest and low wages. This experiment shows how algorithms manage to influence electoral choices in a significant way and they do it more, with very high percentages, in the case of the weakest and least aware people. This result is based on the fact that impressionable people tend to believe in the objectivity and correctness of the choices of a search engine, and this attitude can represent an element of risk for democratic societies in which the information selected by ranking algorithms, such as Google's PageRank and BERT, are used by the vast majority of the population (around 75\% in the US and 90\% in Europe).

The response from search engine owners, such as Google, is that they simply provide users with links to the most relevant web pages. In this case it should be noted that relevance is not an objective fact but is decided by their algorithms, by the choices of those who designed and implemented them. The main problem with this type of situation lies in the fact that no administration or public authority can verify how Google algorithms compute the relevance choices. Unregulated election-related search rankings or harmful posts on social media can pose a significant threat to the democratic system of government. A search engine or a social platform can become a great voter, a gigantic electoral agent a digital collector of consensus and votes that only a few (e.g., the European Union) today seem to be very interested in regulating. More generally, we don't worry much about the fact that search engines can alter citizens' opinions and behavior without them being aware of it. Still, this is a scenario that could prove much more worrying in the coming years.

\section{\label{sec:8.6}Politicians Replaced by AI?}

European Tech Insights 2021, presented by IE University, explored how citizens across nine European countries (France, Germany, Poland, Italy, Spain, Estonia, the Netherlands, Sweden, and the United Kingdom) feel about digital transformations and how they think their governments should deal with them. Approximately 3,000 citizens were interviewed to find out what people thought about the impact of digital technology on society and how it is shaping their lives in terms of automation, democracy, and the influence of big tech companies. A crucial question was: ``How would you feel about reducing the number of national parliamentarians in your country and giving those seats to an artificial intelligence algorithm that would have access to your data to maximize your interests?'' According to the responses, 51\% of Europeans support replacing their parliamentarians with algorithms. Younger generations particularly support this. The proposal was particularly popular in Spain (66\%), Italy (59\%), and Estonia (56\%), whilst the citizens of Germany, the Netherlands, the UK, and Sweden were mostly against. The results vary significantly by age, with the younger people being more open to the idea. Over 60\% of Europeans aged 25--34 and 56\% of those aged 34--44 are excited about this measure, whereas a majority of respondents above 55 years old are against it. Another question related to the previous one was: ``Artificial Intelligence (AI) can make data-driven decisions with accuracy often surpassing humans. Would you rather have a human or Artificial Intelligence make a decision on approving social welfare payments or approving visas for working in a foreign country?'' In this case, one-third of Europeans would prefer to have an AI rather than a civil servant decide on their social welfare payments or approving their visa. One quarter of Europeans also trust AI more than humans when it comes to negotiating and granting mortgage loans. The strongest trust in AI is seen in Estonia, Italy, and Spain. Up to 41\% of Spaniards and 37\% of Italians and Estonians are in favor of having AI decide on their social welfare payments. Even knowing that AI algorithms are procedures that are often opaque and do not respond ``personally'' to their choices, the majority of European citizens would replace politicians with them. From the results of this study, we have some understanding of how deep the gap between representatives of power and ordinary citizens is, to the point of leading them to consider replacing a politician with a software program capable of making decisions on the basis of automatic rules. The question becomes even more worrying for the proponents of political power if we look at the attitudes of young people regarding the use of algorithms instead of human representatives. In some respects, the data obtained from the IE University survey show a high degree of confidence in the capabilities of digital technologies. This aspect can be to some extent related to the hegemony of algorithms we have discussed before.

Considering that 51\% of Europeans would be in favor of delegating political decisions to AI algorithms and given the ever-increasing isolation of the political elites in Europe, it was only a matter of time before someone moved from words to deeds. This happened in Denmark in May 2022 when The Synthetic Party (\textit{Det Syntetiske Parti}) was founded, a new political party led by an AI chatbot algorithm responsible for the development of its political program. The artist collective Computer Lars together with the art and tech MindFuture Foundation were the creators of The Synthetic Party. The party's public face and figurehead is the chatbot Leader Lars (a conversational AI serving as the nominal leader of the party) that has been programmed on the policies of Danish fringe parties since 1970 and is meant to represent the values of the 15\% to 20\% of Danish citizens who generally do not vote in the election. Due to legal rules, Leader Lars won't be on the ballot, but the human members of The Synthetic Party are committed to carrying out their AI-derived political program.

People can speak with the Leader Lars chatbot on the chat app Discord (discord.com), addressing the software-made leader by beginning sentences with an ``!''. The Leader Lars chatbot understands Danish and English but writes back in Danish. Some of the political proposals that The Synthetic Party is planning include a universal basic income of 100,000 Danish kroner per month, which is equivalent to 13,700 US dollars, and is over double the Danish average salary. Another proposed policy change is to create a jointly owned Internet and IT sector in the government that is on par with other public institutions. The Synthetic Party is also promising a minimum income paid to students continuing in education. Leader Lars also advocates the use of a modern version of a kleroterion, a randomization machine that in Ancient Greece was used to select citizens at random to be part of city councils, state offices, and court juries. The party's algorithm suggested using this system to see all members of the Danish Parliament replaced every month by members of civil society. Of course, this version of the kleroterion would integrate AI algorithms for selection. The Synthetic Party's mission is also dedicated to raising more awareness about the role of machine intelligence in political participation and how governments can hold AI accountable for biases and other societal influences. The party also aims to add an 18th Sustainable Development Goal (SDG) to the United Nations goals to be achieved by all nations by 2030. The new proposed SDG is called ``Life with Artificials'' and focuses on the relationship between humans and AI and how to adapt and educate people to interact and work with machines. Asker Staun{\ae}s, a researcher at the MindFuture Foundation and one of the creators of the Synthetic Party, declared that ``Leader Lars is the figurehead of the party. \dots\ Denmark is a representative democracy, so would have humans on the ballot that are representing Leader Lars and who are committed to acting as a medium for the AI.'' The futuristic scenario described by Staun{\ae}s aims to reverse the roles of humans and machines, assigning the latter the leading role in the political choices and decisions that affect humans.

\begin{thebibliography}{}
\bibitem[Anders(2002)]{chap:8:Anders:2002} G. Anders. 2002. \textit{L' Obsolescence de l'homme: Sur l'\^{a}me \`{a} l'\'{e}poque de la deuxi\`{e}me r\'{e}volution industrielle}. Nuisance, Paris.

\bibitem[Epstein and Robertson(2015)]{chap:8:EpsteinandRobertson:2015} R. Epstein and R. E. Robertson. 2015. The search engine manipulation effect (SEME) and its possible impact on the outcomes of elections. \textit{Proc. Natl. Acad. Sci}. 112, 33, E4512--E4521. DOI:~\href{https://doi.org/10.1073/pnas.1419828112}{https://{\allowbreak}doi.{\allowbreak}org/{\allowbreak}10.{\allowbreak}1073/{\allowbreak}pnas.{\allowbreak}1419828112}.

\bibitem[Gramsci(2011)]{chap:8:Gramsci:2011} A. Gramsci. 2011. \textit{Prison Notebooks}. Columbia University Press.

\bibitem[\hbox{Herrnstein and Murray}(1994)]{chap:8:HerrnsteinandMurray:1994} R. J. Herrnstein and C. Murray. 1994. \textit{The Bell Curve}. Free Press.

\bibitem[Marcuse(1964)]{chap:8:Marcuse:1964} H. Marcuse. 1964. \textit{One-Dimensional Man: Studies in the Ideology of Advanced Industrial Society}. Beacon Press, Boston.

\bibitem[Nye(2009)]{chap:8:Nye:2009} J. S. Nye. 2009. \textit{Soft Power: The Means to Success in World Politics}. PublicAffairs.

\bibitem[Parashar and Hariri(2007)]{chap:8:ParasharandHariri:2007} M. Parashar and S. Hariri (Eds.). 2007. \textit{Autonomic Computing: Concepts, Infrastructure, and Applications}. CRC Press.

\bibitem[\hbox{Santini and Carvalho}(2019)]{chap:8:SantiniandCarvalho:2019} R. M. Santini and H. Carvalho. 2019. Online platforms for citizen participation: Meta-synthesis and critical analysis of their social and political impacts. \textit{Commun. Soc.} 36, 163--182. DOI:~\href{https://doi.org/10.17231/comsoc.36(2019).2350}{https://{\allowbreak}doi.{\allowbreak}org/{\allowbreak}10.{\allowbreak}17231/{\allowbreak}comsoc.{\allowbreak}36{\allowbreak}(2019){\allowbreak}.{\allowbreak}2350}.

\bibitem[Selznick(1957)]{chap:8:Selznick:1957} P. Selznick. 1957. \textit{Leadership in Administration: A Sociological Interpretation}. Harper \& Row.

\bibitem[Weber(2019)]{chap:8:Weber:2019} M. Weber. 2019. \textit{Economy and Society}. Harvard University Press.

\end{thebibliography}

%\end{document}

