%\documentclass{acm-book-v2}
%\RequirePackage[errorshow]{tracefnt}
%%\newcommand{\mpage}[1]{}
%%\newcommand{\indexfn}[1]{}

%%\usepackage{showframe}

%\usepackage{custom-tooltip}
%\usepackage{custom-tooltip-Alt-Text-View}



%\begin{document}

\setcounter{chapter}{8}

\chapter{\label{chap:9}Ruling Algorithms}

\noindent{The pervasive use of smart and powerful algorithms is having a large impact on society. In many cases, algorithms discipline human behavior while they help people to solve their problems. This chapter discusses how governments, big companies, and autocratic regimes influence people, laws, and markets by using algorithms and machine intelligence methods that are very often used to carry out private and public tasks. The risks of ``algocracy'' are also introduced and discussed.}

\section{\label{sec:9.1}From Surveillance Capitalism to Politics}

Shoshana Zuboff defined \textit{surveillance capitalism} as the extensive and pervasive collection of personal data and their transformation into objects of trade or commodities, introduced by Google in 2001 and now practiced by several tech companies. The professor \textit{emerita} at Harvard Business School described this new kind of marketing-oriented surveillance method as ``the unilateral claiming of private human experience as free raw material for translation into behavioral data. These data are then computed and packaged as prediction products and sold into behavioral futures markets.'' Although Zuboff in her analysis is more concerned with surveillance by corporations than government surveillance, the large use of personal data and the massive manipulation of digital platforms, such as social media, by political parties and their supporters spread the surveillance paradigm to politics and government practices. From the economy, the model of surveillance capitalism has been extended to politics, introducing authoritarian elements that become governmental actions which can weaken democracies and strengthen totalitarian states. Digital surveillance has spread beyond the tech companies to new surveillance-based systems useful for manipulating people and democratic rules. There are several cases that show how governments, parties, and politicians have embraced the model of citizen surveillance and from mass surveillance have moved to manipulation. The case of the Russian bots, the Cambridge Analytica scandal, the Chinese Social Credit System (SCS), and propaganda systems, such as the very evocatively named ``The Beast.'' Used in Italy by Matteo Salvini, the secretary of the Lega and Italy's Deputy Premier, are all significant examples of how politics is taking over the Internet and social media to implement the surveillance capitalism model for political purposes. In particular, ``The Beast'' is a set of collaborative software for automating cross-posting, meme creation, event advertising, and social communication. Political agents inundate the web and social media with news, posts, and messages aiming to influence opinions, spread fake news, inoculate prejudices, participate in making threats and engaging in offences that are not necessarily criminal, and other ``digital atoms of misinformative poison'' that have led the planet to the phase of \textit{digital} \textit{psychopolitics}, well described in a short essay by the Korean philosopher Byung-Chul \citet{chap:9:Han:2017}. \textit{Psychopolitics} denotes the psychological aspects of political power, including propaganda and brainwashing. Han argues that psychopolitics ``can intervene in psychological processes themselves'' to predict, regulate, and induce human behavior through the influence of the psyche by exploiting massive collections of personal Big Data, machine learning algorithms, and global surveillance technologies. Han wrote that ``the possibility of deriving behavioral models from Big Data announces the beginning of a digital psychopolitics'' in which AI algorithms play a key role. Our online behaviors are observed, collected, and stored in digital formats; they are then analyzed to build human profiles. According to Han, ``Seeing coincides with monitoring. Each one supervises each other'' in a sort of digital surveillance made of emails, posts, tweets, text messages, videos, vocal tracks, and geolocations.

Some political parties, governments, and, more generally, politicians use digital systems to analyze news, posts, photos, videos, and tweets that receive the highest interest and reactions and what kinds of people interact with them. In this way, they can comprehend and influence the feelings of citizens on the Internet and social media and, if needed, adapt their political strategy through propaganda. For instance, if after posting a Facebook message discussing immigrant issues, the largest number of comments is ``immigrants steal our work,'' the subsequent post will argue about the shortage of jobs in the country to feed and reinforce that fear. Thus, continuing in a loop that engages many thousands of individuals who are often unaware of this political manipulation of their psyche. It is sufficient to observe, for example, what happens on social media when national tragedies occur in the US because of racism or in Europe with the blocking of the ships carrying immigrants to understand how the Internet is now the place of psychopolitics. As Byung-Chul Han suggested, digital psychopolitics makes us believe that we are free. It leaves us to imagine being able to express our opinions and to have a role in our community. In reality, there are the political powers that exploit the network as a powerful tool to count us, to measure our opinions and our sentiments, and, after having measured them, to manipulate us with a careful and hidden precision that sometimes leaves us happy and unaware that we have become objects of digital procedures that we do not manage and do not understand. People live their ``digital participation'' as a sequence of momentary emotions, canceling the feelings that need time, senses, and complete discourses, but they often do not realize this. Digital media increasingly influence and shape the consensus mechanisms in the society of the new millennium.


Regarding political participation, political parties have reduced their traditional capability of democratic representation. However, digital democracy is unable to define well-formed and stable structures for effective participation, public debate, and decision-making. The \textit{digital polis} is populated by millions or billions of users and contributions but almost never manages to overcome the huge entropy that it produces to become a place where opinions and proposals can be structured and well established to exit the digital world and enter the real world to influence and modify it. Techniques and tools implementing digital communication seem to facilitate the personalization of politics, providing channels that can support personal parties, in which the leader talks directly to their ``digital people,'' bypassing intermediaries. It is even possible to reach a situation in which every individual online is itself a party. Thoughts, comments, and reactions often run after each other without any form of coordination or production of factual results.

In many cases, algorithms discipline human behavior while they help people to solve their problems. Extensively used software, such as the Google search engine, TikTok, and Facebook, are reorganizing the world, not just augmenting human abilities and interactions. Automatic procedures are replacing the social and political life of the community and are changing governance rules and practices. For example, the Internet and social media algorithms push us to, to digital frenzy and typing, and, unfortunately, we very often support their digital processes. Even though the dissemination of content on the Internet is enormous and it may seem impossible to limit its harmful uses, there must be ways out, however difficult, of surveillance capitalism and psychopolitics. Solutions must be envisioned and implemented to avoid the many threats we are experiencing and the daily risks of being manipulated by entities that hide behind the comfort of digital technology and the easy use of social media and can create a new form of power, called \textit{algocracy}, where algorithms are the main tools for government.



\section{AI Technology for Citizens' Surveillance}
Several advanced machine learning techniques, such as deep neural networks, clustering, and classification algorithms, are used to implement smart surveillance systems based on facial recognition, crowd counting and detection, transportation monitoring, or sentiment analysis from social media content. In particular, video surveillance technologies based on deep learning for facial recognition are widely used in buildings, streets, and public spaces. In the past, most video surveillance systems conveyed images and videos to a central server for video analysis. However, as the scale of video surveillance systems increases, smart cameras increasingly enable processors to locally run video analytics and learning for faces, objects, vehicles, or crowd detection. China was reported to have deployed a massive surveillance system composed of over four hundred million cameras, with millions more expected to be installed in the future. The key technique they use is video-based face recognition. Face recognition systems are deployed not only in China but also in other countries. For example, in India the NeoFace Watch system provides the police with real-time alerts regarding suspicious lawbreakers or activities detected in areas under surveillance. In 2013, the Singapore government implemented a Safe City Test Bed in which video surveillance and video analytics techniques are widely employed for monitoring the city. In these surveillance systems, machine learning algorithms for video recognition are combined with video management systems to improve face, body, and object recognition. Machine intelligence algorithms are implemented through a layered approach where the bottom layers identify pixels and frames and the higher levels detect and categorize visual patterns or portions of images up to the highest software layer that recognizes complex elements (e.g., faces, bodies, and vehicles) in an image or a scene of a video. For example, Gaussian mixture model algorithms can be used to identify individual or groups of pixels, whereas convolutional neural networks can be used for pattern recognition and image classification. Typical machine learning techniques used for face detection include neural networks, support vector machines, and AdaBoost classifiers. These techniques, together with Bayesian classifiers, hidden Markov models, and other learning algorithms, are also used for pattern recognition, obtaining accuracy values up to 99\%. Some surveillance systems also use activity recognition algorithms to recognize the actions and objectives of one or more individuals and for tracking them by a set of observations on their actions and the environmental settings [\citealt{chap:9:RamamurthyandNirmalya:2018}].

Video surveillance systems are not the only technology that utilizes AI algorithms for citizen surveillance. Predictive analytics is widely used for the analysis of large datasets when searching for suspicious text, behavior patterns, or anomalies to assess security-related risks. For example, in the Netherlands, the police implemented a predictive policing tool (\textit{Criminaliteits Anticipatie Systeem, }CAS) that they use to analyze large datasets, including historical crime data, to help predict crimes and decide where to deploy police officers or identify individuals who are supposedly more likely to commit or be a victim of a crime. The CAS system uses the SPSS package and runs artificial neural networks to learn to recognize crime patterns. It is also supported by an Oracle Database for storing and retrieving data. After the modeling steps, the geographic maps generated in the system are compiled using MapInfo. Other similar systems are used in many other countries. Previously, we discussed the COMPAS system used in the US. In the aftermath of the Twin Towers terrorist attacks, the US introduced policies and software systems to collect and transmit to the government and intelligence agencies detailed data on airline passengers. The data are analyzed by classification and clustering algorithms to produce risk categories and identify suspicious passengers in real time during border control checks.

Since 2018, the Italian National Police has used a facial recognition system during investigations. It is called SARI (\textit{Sistema Automatico Riconoscimento Immagini}---Automatic Image-Recognition System) and has been developed to identify unknown suspicious individuals by matching their photo with facial images collected in the Automated Fingerprint Identification System (AFIS) database. The SARI system, by querying the AFIS database, provides a list of images classified according to similarities. The selected images are then analyzed by specially trained forensic police officers. The AFIS database includes fingerprints, other personal details, identifying features, and facial images of individuals with a criminal record in Italy. AFIS stores unique facial images for approximately 10 million people, 2 million of whom are Italian nationals and 8 million are foreign nationals. Due to its geographic position in Europe, Italy is at the receiving border of constant migration flows coming from Africa and Asia. For this reason, the SARI system is also used as a recognition system for migrants. The practice of digital surveillance on migrants is a noteworthy case because migrants and asylum-seekers are considered by governments as categories of people that must be identified, tracked, and surveilled in the same way as criminals. A lack of transparency about who is included in the AFIS database, lack of information and analysis on the accuracy of the machine learning algorithms (we only know that the SARI system uses convolutional neural networks for facial recognition), and the absence of answers from law enforcement agencies has raised concerns about the privacy and legal risks that the SARI system might introduce whenever it is used on migrants and foreigners in Italy. We must also consider that in Italy asylum-seekers can be questioned and imprisoned just because the SARI system algorithm has matched them with the photo of a suspect with whom a migrant or an asylum-seeker may share facial characteristics such as form of face and/or color of skin. Moreover, police in Italy had initially planned to use a more invasive version of the facial recognition system called SARI Real-Time, which would have allowed for real-time identification of migrants upon their landing on Italian ports. Use of the SARI Real-Time system was disallowed following a decision by the Italian Data Protection Authority (DPA), which is an independent authority set up in 1997 to protect fundamental rights and freedoms in connection with the processing of personal data and to ensure respect for individuals' dignity. The DPA stated that the SARI Real-Time system can allow unjustified mass surveillance and that there was no legal basis to deploy it in Italy. The DPA decision aimed to protect both Italian citizens and migrants who are in a vulnerable status upon arriving on Italian shores.

Control of content posted to the web and on social media platforms is another surveillance technique based on text mining and social media data analysis. Governance policies in this case are implemented by content analysis (e.g., tweet analysis, meme detection), content removals, content curation through de-platforming, that is, blocking or removing the users' account, relegation, or banning the account to reduce the visibility of its contents. A very long list of cases has been documented where governments and public agencies sent requests to social media platforms asking them to remove content and/or specific accounts on the basis of national laws or security measures. Automatic monitoring and scraping of publicly available content uploaded, for example, by people on social media platforms is also carried out by police and government agencies in several countries through the use of data analytics and machine learning algorithms. Both in democratic and totalitarian countries (as discussed in Section~\ref{sec:9.5}), governments analyze digital content (emails, social media, web blogs), scouring for information that can be critical for social or political order. For example, the National Coordinator for Counterterrorism and Security in the Netherlands uses social bots and fake social media accounts to track social activists to identify opinions and activities through their online accounts. In the fall of 2022, the Turkish parliament approved a social media law that the government bills as a fight against disinformation and the opposition calls a censorship law. The law imposes heavy sanctions on reporting against the government and sharing it on social media; people who help these critical news stories spread on social media will also be deemed to have committed a crime. There are many other cases of citizen surveillance where the involvement of digital technology and, in particular, machine intelligence is crucial. Governments around the world have been adopting personal and mass surveillance systems based on Big Data analysis techniques and machine learning algorithms. By exploiting these ``intelligent'' solutions, governments and security agencies can deploy more accurate surveillance strategies that can discover minute details and identify intimate behaviors and some very private aspects of people. These results are achieved by accessing massive and pervasive sources of data and information available on online platforms and personal devices and using complex algorithms that are at the core of surveillance policies.

\section{\label{sec:9.3}Algocracy}

Algorithms define the actions to be performed to reach a given goal; however, they also specify and delimit the information to be acted upon. When algorithms interact with many people or execute public procedures, they act in the ``public sphere.'' They contribute to ``social sorting'' by influencing the life of small or large portions of the population. In these cases, algorithms take the role of institutions because they have the power to stimulate inclinations, structure mass behavior, guide opinions, and induce and control human decisions. In his essay on the ethics of algorithms, Mike \citet{chap:9:Ananny:2016} noted that ``Algorithms `govern' because they have the power to structure possibilities.'' They implement sequences of instructions that create organized actions, predict future behaviors, and arrange solutions for individuals, organizations, or nations. Algorithms act in all online procedures and in very many public workflows. In many contexts managed by digital technologies, algorithms impact the organization of citizens, for example, with the generation of information echo chambers that preclude fair discussion, especially for less educated citizens. Software programs influence people with their imperative prescriptions in supporting decision-making in several domains of the public sector including education, benefits provision, and justice.

The term algocracy originates from the word ``algorithm'' and the Greek suffix -\textit{kratia} that is a derivative of the Greek \textit{kratos}, meaning power, rule, or authority. Thus, whereas bureaucracy denotes the exercise of power through the office and democracy indicates a form of power exercised directly or indirectly by the people (\textit{demos}), algocracy refers to power exercised through computer-programmed algorithms. The analysis of algocracy reveals how the governmental principles of organizations that rely on algorithmic systems differ both from democracy and traditional bureaucracy. Algocracy is then a societal system in which algorithms structure, facilitate, and/or constrain the ways in which humans operate. In algocracy scenarios, authority is exercised through algorithmic systems that codify legal, organizational and also professional rules as sequences of lines of code written, for instance, in Java, Python, or SQL. Algocracy describes an ecosystem in which algorithms are used to gather, warehouse, organize, and analyze datasets through which decisions are made. In implementing these tasks, algorithms organize and limit the ways in which individuals and organizations involved within those ecosystems interact with one another and define operations and relationships of the broader community affected by algorithmic processes. This allows, for example, high centralization in decision-making and in control because work that is expertise-based in the bureaucratic setting is automated in the algocratic scenario.

Under the algocratic style of governance, human activities at home or at work are controlled or supervised not by notifying the citizen or the worker to perform a task nor necessarily by limiting the citizen or penalizing the worker for their inaccuracy, ignorance, or error. Instead, activities are controlled by deploying a structured frame in which there are no alternatives to performing the activity or the work as recommended. For example, the software that assists a police officer in filling information about a robbery suspect obliges them to complete the required fields and guides their actions in precise ways. The same occurs when a citizen uses a program for tax payments. Data must be provided in a rigid way, and there is no way to provide values that are not expected by the program although they might be useful for a tax officer to better evaluate a declaration by a citizen. By using programming languages, code developers empower our digital machines with the capacity not only to identify and signal the incorrect values inserted or the improper steps taken by a user, but also to suggest the appropriate values or methods to a naive user. The authority of the computer, which by exploiting a very large set of circuits is able to assume the role of a controlling entity, turns the relationship with digital machines on its head. Programming then emerges as a new type of power that configures possible forms of action in an authoritative way that is able to govern bureaucratic procedures and manage surveillance systems.

Algocracy is an organizational model that regularly performs routine tasks, although with the large use of AI algorithms it designs and deploys non-routine tasks (e.g., this can be done by using machine learning, recommendation systems, predictive data analysis, and natural language processing). Algocracy is characterized by a high standardization of work where processes are deeply regulated and based on coded rules that can be adaptive to the different contexts that may occur. Algocracy can benefit from advanced AI technologies and from pervasive computing models such as cloud computing, IoT, and edge computing because they enable further expansion of digital procedures into the domains of expert decision-making, where algorithms are designed to assist or substitute officials, professionals, and managers. This trend occurs in several domains, and also in very complex ones such as medicine, where, for example, the implementation of advanced visualization techniques supporting augmented decisions enables the absorption of a pathologist's complex diagnostic process and facilitates a detailed examination of the multidimensional features describing a pathology process.

In the algocracy model, the algorithmic systems are also associated with high levels of centralization. Design choices and decisions are made at high management levels of the professional bureaucracy and IT specialists. Moreover, operation control and logic formalization are high. Automated functioning basically provides standard sequences of actions that allow the avoidance or sanction of deviating social actions. Although dynamic sequences or adaptive ones can be coded, this approach stimulates compliance and offers different control strategies to the top- or medium-level managers, which play a complementary role in algocratic governments. In algocracy, an important role is also played by data and information. The information source of algocratic systems is not limited to local data; it uses each available data source stored in local computers or on the Internet. Data collection can exploit the vastness of data coming from the web, databases, emails, and social media that can be accessed, queried, filtered, and warehoused in structured models useful to the algocratic computational processes. The analysis of these massive amounts of data can be programmed and adapted to a certain degree by the developers of machine learning algorithms whose perceptions, predictions, classifications, and viewpoints enter the algocratic system and define its knowledge base and operative processes.

Algocracy scenarios are shaped by collections of algorithms that computationally produce signals and provide automated support for decisions based on the computerized analysis of data. The automated signals are basic mechanisms because they represent the primary advice to be handled. This means that social actions and processes within an algocratic system are guided by signals that, for example, are obtained from the execution of AI algorithms, such as clustering or association rules, on domain-specific datasets. Due to this algorithm- and data-intensive evaluation, signals produced by algorithms provide suggestions, predictions, and support actions operated directly by computers or carried out by humans. For example, automated advice may decrease vagueness or indecision by providing (possibly correct) solutions and formalizing non-routine activities. Daily routines, labor, and other activities  in algocratic systems are subjected to larger control, which makes the entire society more submissive toward its leaders and political governments. Therefore, in comparison with human-driven environments, algocratic systems reduce and compute (measure) the uncertainty of decision-making actions and processes. In this way, algocracy further rationalizes and provides code-based structures to the practice of logical-political authority. This new scenario, in which signals and decisions are based on Big Data analysis and machine learning, depicts a new model of governance that may appear more efficient but exposes itself and citizens to great risks [\citealt{chap:9:Danaher:2016}].

As mentioned in \citet{chap:9:Lorenzetal:2021}, there has been no extensive research work into the effectiveness of algocracy. This is a topic where theoretical and practical studies are necessary due to the importance of algorithms in organizations and, in general, for governance. The increased automation of life and work triggered by the large use of computational systems and AI algorithms that perform actions that mostly cannot be refused are reducing the decision space of humans and limiting their freedom. For these reasons, algorithmic rationality can be argued to result in wrong or senseless decisions despite the rational premises and approaches that are embodied in algorithms. As discussed in other sections, algocracy systems may suffer from a lack of transparency, explainability, and accountability. This, for example, can occur when people use AI algorithms that are not open source or are based on black-box programs, which occurs with deep learning networks using millions or billions of internal parameters. In these cases, decision-making is based on multifaceted algorithmic procedures that often cannot be analyzed and reconstructed by using reverse engineering techniques. Clear human responsibilities and accountabilities may no longer hold if complex and opaque algorithms are used in decision-making processes. On the contrary, if something goes wrong with decisions supported by black-box algorithms, for example, in legal decisions or in medical cures, it becomes impossible to identify responsibilities or even find the origin of wrong decisions made by an algorithm (i.e., which lines of code, input data, or internal parameter).

Indeed, if we consider the extent of human intervention in algocratic systems, we must consider that some software systems make this simpler and more significant than others. For example, there must be a distinction between, on the one hand, open-source systems that offer their code to be read by humans or machine learning algorithms such as decision trees or association rules, whose results are clearly interpretable/{\allowbreak}understandable, and, on the other hand, proprietary closed codes or deep learning networks that are not interpretable/{\allowbreak}readable. Algorithms in the first category are based on clear instructions, rationales, and factors that can be understood by human experts, whereas algorithms belonging to the second category cannot be reduced to human explanations. They are based on elements and formal structures that are closed or too complex for humans to understand. For this reason, further work must be done to study and discover the effects of algocracy on intelligent algorithms that may be human readable or not.

According to the above-mentioned characteristics and risks, algocratic systems can threaten the legal and political order. As we will discuss in the real cases described in the next sections, the risk possibilities at both the individual and collective level can create novel and exceptional quantities of control and manipulation that jeopardize democratic societies and also eliminate elements of personal freedom that may still exist in authoritarian regimes. \citet{chap:9:Lorenzetal:2021} discuss the real example of the Berlin police force in Germany, which uses KrimPro, a predictive policing system designed to exploit yearly retrospective analyses of crimes to automate crime analyses on a daily basis. KrimPro has become the main system for coordinating police efforts in Berlin around tackling robberies, and it has greatly influenced the decision-making processes about allocating resources at the level of local police units. The use of KrimPro is a simple case of algocracy where police officers attribute great importance to KrimPro analysis, which means that the course of action is generally determined by the algorithmic decision and advice that can only be overruled with great difficulty, and only with additional justification. The scholars who analyzed the use of KrimPro concluded that ``If the police professionals who are responsible for fighting domestic burglaries reject the prediction and therewith additional units and a crime is committed that might have been prevented by these units, they put themselves in a bad light. On the other hand, the heads of the inspections do not risk anything when they just comply with the assessment provided by the KrimPro report and deploy additional units even if these extra efforts appear to be ineffective.'' This behavior shows that machine intelligence can take the lead in critical domains, and humans, in this case police officers, often must accept automated decisions. Similar scenarios can be found in different domains such as city governance, social security, and judicial decisions. The KrimPro example shows that algocracy may have negative consequences for individuals working in organizations where AI technologies are used to regulate operations. The autonomy of people in algocracy scenarios is reduced, and they tend to act according to the directives provided by the algorithms.

\section{\label{sec:9.4}Governmentality and Algorithms}

In his studies on the mechanisms of exercise of power and on the government of people and societies, in 1978 the French philosopher Michel Foucault introduced the concept of governmentality [\citealt{chap:9:Foucault:2014}]. Governmentality (from the French \textit{gouvernementalit\'{e}}) is a term that was already used in the past, but Foucault used it to recall the link between governing (\textit{gouverner}) and the way of thinking (\textit{mentalit\'{e}}), therefore the relationship between the mechanisms of power and government and the forms of rationality that organize them. In fact, with the term governmentality Foucault meant that specific form of government management which through an ensemble formed by ``institutions, procedures, analyses, reflections, calculations and tactics'' ensures the taking charge of populations and guarantees the ``government of the living'' having ``in the political economy the privileged form of knowledge and in apparatuses of security the essential technical instrument.'' When Foucault uses the term government, he refers in a broad sense to the ability to ``structure the possible field of action of others'' and therefore to govern the conduct of people. Foucault proposed the concept of governmentality to explain the particular way of administering ``the living'' (in the sense of the governed) that has occurred particularly in modern European history. Governmentality is a  set of practices, regulations, and technologies for governing citizens' lives that were implemented in Europe between the 16th and 19th centuries in the exercise of government in its form of liberal technique. Through governmentality, the state combines into a single whole the knowledge, techniques, and practices capable of ensuring or promoting conditions deemed favorable for the life of a population. It becomes a regulatory state capable of controlling without violence and organizing the living spaces of citizens by regulating their life together with their conduct.

Governmentality also has a significant relationship with the concept of biopolitics elaborated by Foucault himself. In the \textit{Lectures on the Will to Know}, \citet{chap:9:Foucault:2013} described biopolitics as a power in which ``the ancient right to take life or to let live has been replaced by a power to foster life or disallow it to the point of death.'' In his other work, \textit{The Birth of Biopolitics} [\citealt{chap:9:Foucault:2008}], he wrote ``The new governmental reason needs freedom, therefore the new art of government consumes freedom. It consumes freedom, which means it must produce it. It produces it, it must organize it. The new art of government therefore appears as the management of freedom.'' In the 21st century, the exercise of power, the management of people's freedom, biopolitics, and therefore also governmentality, as proposed by Michel Foucault, have witnessed the birth and growth of an eloquent and increasingly relevant relationship with the broader use of digital technologies that is made by people, companies, and states. This recent relationship is realized through the ways in which the main elements of information technology, such as computers, algorithms, the Internet, Big Data, and machine intelligence, are transforming the relationships between individuals and between them and the governing bodies of public and private life. This is done through the pervasive forms with which online life is redefining people's freedoms and is influencing the forms of exercising power through the many extra-state practices that find their implementation tools in the digital universe, the info-space where they can make explicit the government of the subjects. The study of these issues can help to perform a critical analysis of digital systems as a rational technology of power, as a non-secondary element of governmentality. Everything that hardware and software technologies have been able to put in place contributes to defining, limiting, and/or expanding the operational space of individuals, the organization and governance of their freedoms. This is done through codified procedures that regulate (defining them) the actions of the living. This current context can be described using the term ``digital governmentality,'' which must be explained as a complex modality that defines procedures, practices, analyses, and calculations for the delimitation and management of the government of people through digital systems that are made up of algorithms, software systems, communication protocols, and complex data processing procedures that influence and manage every human activity.

The forms and methods of delivery, control, and management of the digitization processes and of the massive and all-encompassing collection of data show the weakness of the governmentality of the liberal powers that are leaving the governance of these processes to large private companies. Sometimes this is to achieve economic advantages, as occurs in the US, other times it is due to a lack of knowledge and management, as occurs in developing countries and in democratic states with low levels of technical knowledge in the government elite. Conversely, totalitarian governments, among these China, which certainly represents the most appropriate case, have understood how the digitization of society allows greater control and management of the operational spaces of individuals, and this is an element of digital governmentality that can be exercised in the new century. In the digital era, knowledge is increasingly being extracted via machine learning algorithms from large amounts of data. Most of the time this knowledge is not available to individuals (not even those it deals with, those it describes), and they cannot know it, perceive it. However, knowledge extracted from Big Data is still applied to people, their behaviors, relationships, and choices in such a way as to infer other knowledge or probabilistic predictions about their preferences, intentions, desires, and inclinations that would not otherwise be evident. As we have discussed, digital processes do not stop at the inference phase but use its results to act on individuals, to stimulate preferences, condition choices, regulate behaviors, and implement a microphysics of the government of the living that arises online and interferes with people's freedoms and actions. This real-time action is made possible by the enormous spatio-temporal coverage of digital technologies, their immediacy and continuity, their effectiveness and speed. The combination of large amounts of data and high-performance algorithmics defines a new digital governmentality capable of regulating actions and relationships in a procedural and automated way, therefore capable of exercising authority over the living.

Circa 2010, Antoinette Rouvroy and Thomas Berns dealt with a technological declination of the concept of governmentality by defining ``algorithmic governmentality'' to refer to a certain type of (a)normative or (a)political rationality based on automated collection, aggregation, and analysis of large amounts of data to model, anticipate, and pre-emptively influence possible behaviors. In one of their essays, they wrote ``we show that algorithmic governmentality thus focuses not on individuals, on subject, but on relations'' [\citealt{chap:9:RouvroyandBerns:2013}]. Data represents relations and knowledge represents the relations of relations. Rouvroy and Berns' algorithmic governmentality is understood as a mode of governance fueled by the collection and analysis of raw data and metadata whose movements traverse every aspect of human life. The subject of algorithmic governmentality is therefore a ``statistical body'' that defines the single individual as a ``datafied'' individual or the class of individuals with equal characteristics through the analysis of their data. As the data on an individual online is updated as they live, their profile can be continuously updated and recalculated in such a way as to become a multitude of profiles expressed in probabilistic forms. The government of (digital) data and their predictions serves the government of the living, that is, it becomes a form of digital governmentality seen as the management of human beings that ``is exercised positively on life and it plans to control, increase, multiply it'' through the management of data and the execution of the algorithms that process those data with the purpose of governing personal feelings, political relationships, and social relationships, also making use of the countless digital devices that totally surround our planet and humanity. The economic--political system that governs most of the developed states and also the one that rules totalitarian states such as China works through digital governmentality to implement a strategy capable of regulating the governance of economic and social processes and also the management of vital processes of individuals. There are at least two additional and distinct issues to consider. On the one hand, we have the regulation and control capabilities that AI algorithms, IoT systems, search engines, and social media can exert on our world and our lives, influencing decisions, implementing control measures, identifying correlations, and making predictions. On the other hand, there is the action that the expressions of digital governmentality can have on our minds concerning the ways, actions, choices, and desires influenced/regulated through codified procedures (such as worldviews). They depend on the data that are made available and are analyzed to substantiate the decisions and the steps of algorithms that act on the decisions and the action of the subjects on/with whom the algorithms operate/{\allowbreak}interact.

Therefore, to go beyond the theories of Rouvroy and Berns and actualizing Foucault's original intuition, digital neo-governmentality is not only built on the pervasive collection of data and the construction of probabilistic datified subjects, it becomes the regulated production of behaviors and relationships. Automated procedures that become subjects of government above and beside people. They are codified processes represented as objective and unquestionable choices. As operations of regulation of daily life that help us to act and which perhaps we could no longer live without, we would not be able to live and express the possible freedoms. Algorithms act as procedural digitization of the government of the freedoms of individuals and their relationships. The digital code, defined by complex algorithms expressed in different programming languages at every moment of their execution in our devices and in those owned by public and private authorities establishes the terms and limits of the life of billions of individuals in cyberspace, which is now a semantically important and temporally significant part of daily life. Software procedures supported by hardware platforms regulate and implement social values. Designers and developers decide how code affects people, how it performs their tasks, and how it regulates their interactions. Digital governmentality envisages a minimal role of citizens in its choices (e.g., national laws on data privacy, the GDPR, and the AI Act). Individually we do not have the freedom to determine how these codified digital values regulate our spaces of freedom. As single individuals, we don't have the capacity to influence programmers, to determine how they can code software systems to include our values in them, to determine individually (or rather collectively) how the action of governing our relationships should take place, and how to regulate our lives. Digital architectures govern our living space and influence it through their fast and continuous actions that substantiate values in the form of sequences of programmed instructions, which can also have harmful consequences on the practical level and on personal\break freedom.

\section{\label{sec:9.5}The Chinese Social Credit System and Similar Systems}

When China's leader Xi Jinping began his third term in office in Beijing's Great Hall of the People, he invoked his greatest ambition: the construction of a new form of post-modern government powered by data and mass digital surveillance that challenges democracy. President Xi's political program is a mixture of Big Data collection, AI algorithms, and autocracy that promises personal security and state efficiency. Many Chinese cities planned to make their citizen' lives easier and well organized by using digital technologies. Local Chinese governments and private companies in 2020 invested around 24 billion dollars on smart city technology, and these funds are planned to increase up to 40 billion dollars by the end of 2024. A symbol of digital innovation in China is Hangzhou, the capital of Zhejiang province. The city is fully connected by a pervasive network of sensors meant to improve the quality of life of residents, but it is also used to control them. This network collects massive amounts of data processed by machine learning algorithms that improve traffic, monitor potential crimes, and support city planning activities. The collaborations between big companies such as Alibaba and the city government have transformed Hangzhou into one of the smartest cities in China. The city's camera surveillance network has been useful in finding missing children and the data it collects are a valuable source of information for improving public services. Together with this positive side of the intensive use of digital surveillance, the dark side of China's surveillance strategy must be also considered, as exemplified by what is occurring in the region of Xinjiang, where authorities have implemented a campaign of compulsory integration of the Uyghur population and other Muslim groups. Members of these ethnicities are tracked by facial and voice recognition systems. Their mobile phones are scanned by police for evidence of religious expression or interaction with external entities. As a consequence of digital tracking, communicating on Skype with relatives overseas or being seen by CCTV going to the post office to send a letter abraod can get Uyghurs in trouble. This is a clear case of the political use of Big Data and algorithms that play the role of controllers of large groups of population. Similar techniques have been used to track people in several Chinese cities who marched to protest against the government's strict COVID-19 policies. City cameras using facial recognition together with phone trackers along the streets were used by police officers. Phone trackers are devices that emulate a cell tower and connect to the phones of people who pass by to record smartphone data for the police to check.

An important case of digital technology applied to a large population is China's Social Credit System (SCS), which is used to digitally track and record businesses, individuals, and government institutions for the purpose of evaluating their trustworthiness. In 2014, the government of the People's Republic of China announced a six-year plan to build a system to reward actions that build trust in society and penalize oppositional behaviors. The first paragraph of the document ``Planning Outline for the Establishment of a Social Credit System (2014--2020),'' issued by the State Council, explains that ``The social credit system is an important component of the Socialist market economy system and the social governance system. It is based on laws, regulations, standards, and agreements; its foundation is a complete network covering the credit records of all members of society and the credit infrastructure; it is supported by the application of credit information and credit service systems in accordance with rules; it inherently requires establishing the concept of a culture of creditworthiness and promoting the traditional virtue of creditworthiness; its reward and punishment mechanisms are incentivizing trustworthiness and restricting untrustworthiness, and its goal is to raise awareness of creditworthiness and the level of credit throughout society.'' This outlines a vibrant political program that aims to have a large impact on the Chinese population.

The SCS is an example of the implementation of governmentality concepts by exploiting machine intelligence solutions. It is a mix of attempts to regulate the financial credit industry, enable government agencies to share data with each other, and promote state-sanctioned moral values. The SCS rates individuals based on the collection, aggregation, and analysis of large amounts of data. In some cases, the evaluation of individuals has been expressed by a single numerical score, usually between 1 and 1000, or using a letter grade that usually goes from A to D. Data and information about businesses and citizens are collected from a range of different sources including individual businesses and government entities. Although there is no complete information on the definition of rankings and the evaluation process, the \textit{South China Morning Post} reported that organizations that determine the rankings include China's economic planning team, the National Development and Reform Commission (NDRC), the People's Bank of China, and the Chinese court system. The report titled ``State Council General Office Guiding Opinions Concerning Accelerating the Advance of Social Credit System Construction and Building Credit-Based Novel Supervision and Management Mechanisms'' [\citealt{chap:9:StateCouncilGeneralOffice:2019}] emphasizes the need for Big Data and artificial intelligence to provide early warning of risky actors in need of extra regulatory attention. At the same time, the document called for improved credit repair mechanisms, enhanced data collection, and privacy protections. The information systems that provide the data layer of the SCS integrates public credit data, market credit information, possible complaints, and related data coming from the Internet and third parties. The final goal of the designers is to integrate and use Big Data repositories, data analysis algorithms, artificial intelligence software tools, and other computing technologies to provide (semi-)automatic procedures for credit supervision, business processes, and citizen behavior tracking and monitoring. Among the goals of the SCS's proposers and designers, Big Data analysis and machine learning must be used to discover and classify signs that laws and regulations are being violated and prevent actions harming the public interests and the security of people's lives and resources. Technologies such as the IoT, the Internet of Vision (implemented as a massive network of connected cameras with facial recognition ability), and management strategies are key elements of the SCS for improving law enforcement as well as supervision and management of people and businesses. The final goal declared in the State Council General Office report is to ``realize the standardization, accuratization and smartification of supervision and management, reduce human factors, realize fair supervision and management, {\dots} realize `entering the door once, inspecting multiple matters,' and reduce disturbance to supervision and management targets'' [\citealt{chap:9:StateCouncilGeneralOffice:2019}]. Sentences such as these ones recall Foucault's ideas of modern governmentality and show how algorithms and Big Data are used to limit people's freedom and human rights through data analysis and machine learning techniques that automatize the relationships among citizens and government.

As we noted, the basic building block of the SCS is data. Through the distributed nodes of the system, data are gathered and shared by central, regional, and city government bodies as well as from private establishments. Big data analysis and machine learning techniques, such as classification, clustering, and link analysis algorithms, are then used to explore the data and discover behavioral patterns, law violation indications, and other traces that are used for citizens'\vadjust{\vspace*{10pt}\pagebreak} and/or \hbox{business} ranking. Several IT companies are involved in the development of the software systems that implement the technological platforms supporting the SCS. Small and medium IT companies commissioned by local and city governments built most parts of the SCS technology infrastructure including databases, \hbox{repositories,} and data centers. Social media companies acted to inform citizens about how the system functioned and if needed provide information on what data they keep about individuals and their behaviors. Alibaba, for example, helps the courts distribute decisions through the people's addresses it stores in its huge social media platform. Douyin, the Chinese version of TikTok, partnered with a local court to publicly shame individuals who defaulted on court judgments. Thus, Chinese governmentality is exercised by a singular combination of public office decisions and private companies' communication techniques.

Collected data and the results of big data analysis are used to add individuals and corporations to credit lists that refer to sanctions, punishments, and rewards. Based on presence in those lists, persons and companies are penalized or rewarded. A citizen or a company with a good credit record in all monitoring fields should receive favored treatment when dealing with the government. At the same time, companies or individuals with low or bad credit records will be punished, for example, being banned from using public transport, consuming luxury goods, using credit cards, participating in public procurement bids, or leaving the country. They will also have their status publicly displayed. The Chinese government published the ``National Basic List of Penalty Measures for Untrustworthiness'' detailing the permissible punishment measures for the purpose of standardizing and delineating the type of penalty measures for untrustworthiness and their targets. The list includes 14 penalty measures for untrustworthiness broken into three classes. The first class deals with measures by which public management bodies implement reductions of a credit subject's rights and interests or increase their obligations in accordance with laws and regulations, such as restricting entry in a marketplace or industry, restrictions on holding positions, restrictions on spending, restrictions on exiting the country, and restrictions on promotion to a higher level of schooling. The second class includes management measures that public bodies can implement to perform their duties, that do not involve reductions of a credit subjects' rights and interests or increasing their obligations, such as restricting applications for government funded projects, restricting participation in awards selections, and restricting enjoyment of beneficial policies and facilitation measures. The third group of measures have been defined to be implemented by organizations other than public bodies, such as inclusion in marketized credit reporting or rating reports. As a practical example, individuals who have failed to pay compensation decided by the court cannot use high-speed trains or planes for traveling. Moreover, they cannot send their children to private schools nor can they apply for a loan or mortgage. Indeed, the social credit score can preclude students from attending universities or schools if their parents have a poor social credit rating. Restrictions on relevant consumer behavior are also possible. Employers are able to consult blacklists when making their employment decisions. Furthermore, some job positions, such as government employment, are restricted for individuals who have a low social credit rating. Some reports in 2022 revealed that more than 30 million businesses in China have already been given a score under some version of the corporate SCS. People who made petitions for personal cases near the site of big meetings at the national or local government level will have 50 points subtracted, while petitions mounted in sensitive areas in the capital Beijing will result in an automatic D ranking. The same applies for petitioners who ``make trouble'' and ``get used by the Internet and foreign media.''

Several Chinese cities have adopted the SCS. For example, Shanghai has the Credit Shanghai that was upgraded in 2020 to its third version. In the city of Suzhou, the system covers all of its 13 million inhabitants. A sort of best practice of the Chinese SCS is Rongcheng, a city with half a million population in the eastern tip of the Shandong peninsula, which has fully implemented that ranking system. In 2013, the city offices ranked inhabitants from AAA to D based on their personal scores. The city started by assigning each resident a base personal credit score of 1,000 that can be influenced by their conduct. People with ranking of AAA are rewarded with some benefits such as free medical check-ups, free water, discount on heating bills, and concessions on bank loans. People with a \hbox{D ranking} lose access to government grants and cannot apply for government jobs or bid for government tenders. They also need to cope with loan restrictions. The city council established rules for adding or subtracting points for residents. For instance, winning a national sports or cultural competition results in getting 40 points, while spreading harmful information on WeChat, forums, and blogs will result in being deducted 50 credit points. Newspapers reported that a resident lost 950 points in three weeks for repeatedly distributing letters online regarding his mother's medical dispute. Rongcheng has installed machines in city hall that are used by residents to print out their credit scores because they need credit certificates when applying for home loans or when they need to request government funding. Near the printing machines are shown the photos of the most honored Rongcheng citizens with their very high scores.

The ever-expanding credit system has awakened the Chinese people's concerns and fears. About 70\% of people who answered a survey initiated by a number of media outlets in 2020 expressed worry about misuse of the SCS. They believe that the concept of credit has been excessively used or even abused. Reporters \hbox{conducted} interviews in Shanghai, Jiangsu, Anhui, and other places and found that most people do not agree with the generalization of punishment for dishonesty. Some people believed that SCS management should not hold every detail of people's lives. The wide use of this algorithmic system may generate unfair results, and in cases of data biases or software errors that will not be easy to identify and correct, it may produce negative impacts on the lives of Chinese citizens.

The SCS is one of the widely used software systems where algorithms play a defining role in controlling the population and influencing their daily lives or future opportunities. Although it is the largest social score system, the Chinese SCS is not the only system used in the world for assigning scores to people. Other examples are the FICO score system introduced in 1989 in the US and the Schufa system used in Germany. Another case of voluntary use of a social credit system is in the city of Bologna, Italy. The Fair, Isaac and Company (FICO) is a computerized credit scoring system used by the majority of US banks and credit agencies to evaluate client creditworthiness and risks. FICO is based on consumer credit files of the three national credit bureaus: Experian, Equifax, and TransUnion. Credit scores in the FICO system are designed to measure the risk of default by considering several factors in an individual's financial history. The algorithms used in the system for calculating credit scores are secret, although some components, such as credit and payment history and debt burden, are included in the ranking procedure. The FICO scoring model assigns each individual over 60 credit scores that are stored in each of the three national credit agencies. The FICO credit scoring system has garnered extensive criticism. US credit reporting agencies have been accused of unlawful behavior by misstating the effectiveness of credit scores that cheated consumers into recurring payments. As the FICO software system computes credit scores from data provided on credit reports using proprietary algorithms, errors on credit reports may have a negative impact on the consumer's resulting credit score, for example, if they compute an inaccurate likelihood that a consumer will default on a loan. This is not a rare event, as US consumers reported that they found several errors on their credit reports and a Federal Trade Commission investigation in 2013 estimated that almost 20\% of consumers had at least one wrong credit report. Above 5\% had errors that positioned them in a lower FICO credit category, making it more likely they would pay more for a loan. More serious cases occurred because of incorrect information matching in the FICO algorithms. For instance, in 2020, a man in Pennsylvania filed a lawsuit against TransUnion, one of the three national credit agencies, over being misclassified as a terrorist due to having the same first name as two persons suspected of being terrorists. When requesting pre-approval for a mortgage, Mr. Ahmed Al-Shaikli of Mount Joy\vadjust{\vspace*{10pt}\pagebreak} saw that his \hbox{applications} were rejected based on data in his credit report. Mr. Al-Shaikli noticed something on his credit report from TransUnion that was not on his reports from the other two credit reporting agencies. TransUnion's report claimed that the name of Mr. Al-Shaikli matched the names of two individuals on the US Department of the Treasury's Office of Foreign Assets Control's list of Specially Designated Nationals (SDNs). SDNs are people prohibited from transacting business in the US for national \hbox{security} reasons. The matches were incorrect. A similar situation had occurred a few years before in California to Sergio Ramirez after TransUnion sold a credit report about him to a car dealership that incorrectly stated that his name matched the names of two suspected terrorists. These cases show how algorithms may influence and rule the lives of people and how an incorrect algorithm may harm people.

The ``\textit{Schutzgemeinschaft} \textit{f\"{u}r} \textit{allgemeine} \textit{Kreditsicherung}'' (Schufa) is a credit rating agency in Germany that plays a similar role as the FICO system in the US. The agency name can be translated as ``Protection Agency for General Credit Security.'' In fact, Schufa assigns a credit score to each resident in Germany. If they have a good Schufa score, it's easier to rent an apartment, buy a car, or get a loan. If they have a bad Schufa score, these transactions become challenging to make and some banks do not allow people to open an account. Schufa tracks German residents' bills over time and, by using these data and processing them through a ranking algorithm, generates and stores a credit rating score for all Germans, rating their ability to pay bills. Personal Schufa records play a vital role in almost every major step in the life of an individual in Germany. The records can be checked by companies when people buy a car, apply for a phone, or apply for a loan. These transactions are easy if the personal Schufa score is from 80 up to 100, they are difficult if the score is lower than 80, and become impossible if the score is 50 or below. Schufa holds data on approximately 70 million people in Germany. This is an extraordinary amount of data that provides Germany's credit bureau an immense power over people's lives. A low Schufa score may mean rejection of credit card applications, difficulties in renting an apartment, and negative responses in commercial transactions. The algorithm used to calculate the Schufa credit scores is proprietary, thus people who undergo its evaluation do not know the rules and sequences of its operations. They do not know how it works and whether there are errors or biases inside its scoring model or in its software procedures. In this case, an algorithm influences citizen's lives and their behavior, but they cannot control how automated decisions are made, nor which automatic directives are applied to their life. Several investigations have reported Schufa mistakes in the credit history of people and identified several anomalies in the data. There have been cases where people were rated rather negatively although Schufa had no negative information on them. Suspicions have fallen on the algorithm, but no clear and complete answer has been provided by Schufa administrators.


\begin{thebibliography}{00}
\bibitem[Ananny(2016)]{chap:9:Ananny:2016} M. Ananny. 2016. Toward an ethics of algorithms: Convening, observation, probability, and timeliness. \textit{Sci. Technol. Hum. Values} 41, 1, 93--117. DOI:~\href{https://doi.org/10.1177/0162243915606523}{https://{\allowbreak}doi.{\allowbreak}org/{\allowbreak}10.{\allowbreak}1177/{\allowbreak}0162243915606523}.

\bibitem[Danaher(2016)]{chap:9:Danaher:2016} J. Danaher. 2016. The threat of algocracy: Reality, resistance and accommodation. \textit{Philos. Technol.} 29, 3, 245--268. DOI:~\href{https://doi.org/10.1007/s13347-015-0211-1}{https://{\allowbreak}doi.{\allowbreak}org/{\allowbreak}10.{\allowbreak}1007/{\allowbreak}s13347-{\allowbreak}015-{\allowbreak}0211-1}.

\bibitem[Foucault(2008)]{chap:9:Foucault:2008} M. Foucault. 2008. \textit{The Birth of Biopolitics, Lectures at the Coll\`{e}ge de France, 1978--1979}. Palgrave Macmillan, London.

\bibitem[Foucault(2013)]{chap:9:Foucault:2013} M. Foucault. 2013. \textit{Lectures on the Will to Know}. Palgrave Macmillan, London.

\bibitem[Foucault(2014)]{chap:9:Foucault:2014} M. Foucault. 2014. \textit{On the Government of the Living, Lectures at the Coll\`{e}ge de France, 1979--1980}. Palgrave Macmillan, London.

\bibitem[Han(2017)]{chap:9:Han:2017} B.-C. Han. 2017. \textit{Psychopolitics: Neoliberalism and New Technologies of Power}. Verso, London.

\bibitem[Lorenz et~al.(2021)]{chap:9:Lorenzetal:2021} L. Lorenz, A. Meijera, and T. Schuppan. 2021. The algocracy as a new ideal type for government organizations: Predictive policing in Berlin as an empirical case. \textit{Inf. Polity} 26, 1, 71--86. DOI:~\href{https://doi.org/10.3233/IP-200279}{https://{\allowbreak}doi.{\allowbreak}org/{\allowbreak}10.{\allowbreak}3233/{\allowbreak}IP-{\allowbreak}200279}.

\bibitem[Ramamurthy and Nirmalya(2018)]{chap:9:RamamurthyandNirmalya:2018}S. R. Ramamurthy and R. Nirmalya. 2018. Recent trends in machine learning for human activity recognition---A survey. \textit{WIREs Data Mining Knowl. Discov.} 8, 4, e1254. DOI:~\href{https://doi.org/10.1002/widm.1254}{https://{\allowbreak}doi.{\allowbreak}org/{\allowbreak}10.{\allowbreak}1002/{\allowbreak}widm.{\allowbreak}1254}.

\bibitem[Rouvroy and Berns(2013)]{chap:9:RouvroyandBerns:2013} A. Rouvroy and T. Berns. 2013. Algorithmic governmentality and prospects of emancipation. Disparateness as a precondition for individuation through relationships? \textit{R\'{e}seaux} 177, 1, 163--196. DOI:~\href{https://doi.org/10.3917/res.177.0163}{https://{\allowbreak}doi.{\allowbreak}org/{\allowbreak}10.{\allowbreak}3917/{\allowbreak}res.{\allowbreak}177.{\allowbreak}0163}.

\bibitem[State Council General Office(2019)]{chap:9:StateCouncilGeneralOffice:2019} State Council General Office. 2019. Guiding Opinions Concerning Accelerating the Advance of Social Credit System Construction and Building Credit-Based Novel Supervision and Management Mechanisms.
\end{thebibliography}

%\end{document}

